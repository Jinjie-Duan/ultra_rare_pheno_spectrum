{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages, context and root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running on Apache Spark version 2.0.2\n",
      "SparkUI available at http://10.128.0.4:4040\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.1-0d9e264\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from hail import *\n",
    "import collections\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import csv\n",
    "import tempfile\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql import SQLContext\n",
    "from pprint import pprint\n",
    "root = '...'\n",
    "hc = HailContext(log=\"/home/hail/hail.log\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 0: Quality control\n",
    "\n",
    "This first part describes the QC of the raw vcf. The code is in ``Hail``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic variant-level QC that we use. This is the general QC applied across the different datasets, but there are additional sample-level filters applied to each dataset, which are not reported here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## raw_vds: input vds\n",
    "## out_vds: output vds\n",
    "## samp_excl_list: list of samples to exclude\n",
    "\n",
    "def basic_qc(raw_vds,out_vds,samp_excl_list=[])\n",
    "    raw_vds = hc.read(raw_vds)\n",
    "    \n",
    "    if samp_excl_list:\n",
    "        vdsT1 = (raw_vds\n",
    "               .filter_samples_list(samp_excl_list, keep=False))\n",
    "    else:\n",
    "        vdsT1 = raw_vds\n",
    "        \n",
    "    (vdsT1\n",
    "    .split_multi()\n",
    "    .variant_qc()\n",
    "    .filter_variants_expr('va.qc.AC > 0 && va.filters.isEmpty()', keep=True)\n",
    "    .filter_genotypes(\n",
    "         \"\"\"\n",
    "         (g.isHomRef && (g.ad[0] / g.dp < 0.8 || g.gq < 20 || g.dp < 20)) ||\n",
    "         (g.isHomVar && (g.ad[1] / g.dp < 0.8 || g.pl[0] < 20 || g.dp < 20)) ||\n",
    "         (g.isHet && ( (g.ad[0] + g.ad[1]) / g.dp < 0.8 || g.ad[1] / g.dp < 0.20 || g.pl[0] < 20 || g.dp < 20))\n",
    "         \"\"\", keep = False)\n",
    "    .filter_variants_expr('va.qc.pHWE > 0.000001 && va.qc.callRate > 0.80 && v.contig != \"X\" && v.contig != \"Y\" && v.contig != \"MT\"', keep=True)\n",
    "    .hardcalls()\n",
    "    .repartition(5000,shuffle=False)\n",
    "    .write(out_vds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Calculate principal components\n",
    "\n",
    "This first part describes the steps used to calculate PCs. The code is in ``Hail``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import 1000 genomes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onekpg = hc.read(root + 'ALL.1KG.qc.hardcalls.vds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put toghether the dataset and 1000 genome to save global PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### vds: input vds\n",
    "### root: root where to export the PCs\n",
    "### samp_excl_list: list of samples to exclude\n",
    "\n",
    "def pc_1000G(vds,root,samp_excl_list=[]):\n",
    "    \n",
    "    if samp_excl_list:\n",
    "        vdsT1 = (vds\n",
    "               .filter_samples_list(samp_excl_list, keep=False)\n",
    "               .variant_qc()\n",
    "               .filter_variants_expr('va.qc.AC >  0', keep=True))\n",
    "    else:\n",
    "        vdsT1 = (vds\n",
    "               .variant_qc()\n",
    "               .filter_variants_expr('va.qc.AC >  0', keep=True))\n",
    "    \n",
    "    vdsT2 = (vdsT1\n",
    "        .filter_intervals(Interval.parse('6:25M-35M'), keep=False)\n",
    "        .filter_intervals(Interval.parse('8:7M-15M'), keep=False)\n",
    "        .filter_variants_expr('va.qc.AF > 0.05 && va.qc.callRate > 0.98 && va.qc.pHWE > 0.001')\n",
    "        .ld_prune(r2=0.2, window=1000000, num_cores=400)\n",
    "        .annotate_samples_expr('sa = {}'))\n",
    "    \n",
    "    \n",
    "    onekpgQ = (onekpg\n",
    "         .annotate_samples_expr('sa = {}'))\n",
    "\n",
    "    ID1=(onekpgQ.sample_ids)\n",
    "\n",
    "    \n",
    "\n",
    "    ID2=(vdsT2.sample_ids)\n",
    "\n",
    "    # Remove individuals in both datasets\n",
    "    intsect = list(set(ID1) & set(ID2))\n",
    "\n",
    "    (vdsT2\n",
    "    .filter_samples_list(intsect, keep=False)\n",
    "    .join(onekpgQ)\n",
    "    .pca(scores = 'sa.pca_1kg')\n",
    "    .export_samples( root + '/pca_1kg.tsv','id=s, sa.pca_1kg.*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate the studies wiht VEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## vds: input vds\n",
    "## out: out annotated vds\n",
    "def run_VEP(vds,out_vds):\n",
    "    (vds\n",
    "    .annotate_variants_expr('va = drop(va, vep)')\n",
    "    .vep(config='/vep/vep-gcloud.properties', root='va.vep')\n",
    "    .write(out_vds, overwrite=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Annotations and creating burden scores for analysis\n",
    "\n",
    "This first part describes the steps used for creating the scores used in the analysis. The code is mostly in ``Hail``, but there are some parts in R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read datasets containing other annotations. These dataset do not contain inidividual-level data and are shared.\n",
    "\n",
    "- `dbNSFP` dbNSFP used for annotation of missense damaging,\n",
    "- `lethal` dominant lethal,\n",
    "- `clinvar` curated clinvar variants\n",
    "- `MPC` missense badness score from Kaitlin samocha\n",
    "- `high_qual_intervals` intervals with good coverage across all exomes captures kits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbNSFP = hc.read(root + 'dbNSFP_3.2a_variant.filtered.allhg19_nodup.vds')\n",
    "lethal = hc.import_table(root + 'lethal_clean.txt',impute=True).key_by('Variant')\n",
    "clinvar = hc.import_table(root + 'clinvar_clean.txt',impute=True).key_by('Variant')\n",
    "MPC = hc.import_table(root + 'fordist_constraint_official_mpc_values.txt.gz',impute=True,\n",
    "                      types = {'chrom': TString(),\n",
    "                                            'pos': TInt(),\n",
    "                                            'ref': TString(),\n",
    "                                            'alt': TString()}).annotate('variant = Variant(chrom, pos, ref, alt)').key_by('variant')\n",
    "\n",
    "high_qual_intervals = (hc.import_table(root + 'high_quality_exome_regions.bed',no_header=True, impute=True)\n",
    ".annotate('interval = Interval(Locus(f0, f1), Locus(f0, f2))')\n",
    ".key_by('interval'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach the dataset and define if variant is in clinvar or lethal, define allele frequencies categories and URV, that is, variants not observed in any of the other dataset. Define also variants that are doubletons in the study but not observed in any other dataset. \n",
    "Note that vds 'annovdslist' are not shared since the include individual-level data. However we made available the variants in the github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## vds: input vds\n",
    "## annovdslist: list of vds used to filter the current vds \n",
    "##        (URV variants are defined as singletons in the vds and not seen in any of the other vds passed in annovdslist)\n",
    "## samp_excl_list: list of samples to exclude\n",
    "\n",
    "\n",
    "def annot_phase1(vds,annovdslist,names_annovdslist,samp_excl_list=[]):\n",
    "    \n",
    "    if samp_excl_list:\n",
    "        vdsT1 = (vds\n",
    "               .filter_samples_list(samp_excl_list, keep=False)\n",
    "               .variant_qc()\n",
    "               .filter_variants_expr('va.qc.AC >  0', keep=True)\n",
    "               .annotate_variants_vds(dbNSFP,root='va.dbNSFP'))\n",
    "    else:\n",
    "        vdsT1 = (vds\n",
    "               .variant_qc()\n",
    "               .filter_variants_expr('va.qc.AC >  0', keep=True)\n",
    "               .annotate_variants_vds(dbNSFP,root='va.dbNSFP')) \n",
    "    \n",
    "    tt = names_annovdslist[0]\n",
    "    tts=tt.split('.')\n",
    "    vdsT2 = (vdsT1\n",
    "             .annotate_variants_vds(annovdslist[0],expr='va.%s=isDefined(vds)' % names_annovdslist[0]))\n",
    "\n",
    "    for num, vdsL in enumerate(annovdslist[1:len(annovdslist)]):  \n",
    "        vdsT2 = (vdsT2\n",
    "                .annotate_variants_vds(vdsL,expr='va.%s=isDefined(vds)' % names_annovdslist[num+1]))\n",
    "    \n",
    "    expression = \"\"\"\n",
    "        va.freq.AF001 = (va.qc.AF < 0.001),\n",
    "        va.freq.DOUBLE = (va.qc.AC == 2),\n",
    "        va.freq.SING = (va.nNonRef == 1),\n",
    "        va.freq.URV = (va.nNonRef == 1 && {0} ),\n",
    "        va.freq.DOUBLEURV = (va.qc.AC < 3 && {1} )\n",
    "        \"\"\" \n",
    "    \n",
    "    annot1vds=(vdsT2\n",
    "    .annotate_variants_table(lethal,expr='va.lethal = table')\n",
    "    .annotate_variants_table(clinvar,expr='va.clinvar = table')\n",
    "    .annotate_variants_table(MPC,expr='va.MPC = table.MPC')\n",
    "    .annotate_variants_expr(\n",
    "        \"\"\"\n",
    "        va.nNonRef = gs.filter(g => g.isCalledNonRef).count()\n",
    "        \"\"\")\n",
    "    .annotate_variants_expr(\n",
    "        expression.format(\"!va.\" + \" && !va.\".join(names_annovdslist),\"!va.\" + \" && !va.\".join(names_annovdslist))\n",
    "    ))\n",
    "    \n",
    "    return(annot1vds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create VEP-based annotations: \n",
    "- `LoF`: frameshift_variant, transcript_ablation, splice_acceptor_variant, splice_donor_variant, stop_gained\n",
    "- `Missense`: missense_variant,inframe_insertion,inframe_deletion\n",
    "- `LOFdamaging`: Lof + missense damaging. Where `damaging` is defined according to the number of different damaging algorithms from dbNSFP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## vds: input vds\n",
    "\n",
    "def annot_phase2(vds):\n",
    "    \n",
    "    annot2vds = (vds \n",
    "    .annotate_variants_expr('va.geneann.transcript_canonicals = va.vep.transcript_consequences.filter(tc => tc.canonical == 1)')\n",
    "    .annotate_variants_expr(\n",
    "        \"\"\"\n",
    "        va.geneann.most_severe_csq = \n",
    "        let x = va.geneann.transcript_canonicals.map(y => y.consequence_terms.toSet) in \n",
    "        if (isMissing(x)) va.vep.most_severe_consequence\n",
    "        else if (x.exists(tc => tc.contains(\"transcript_ablation\"))) \"transcript_ablation\"\n",
    "        else if (x.exists(tc => tc.contains(\"splice_acceptor_variant\"))) \"splice_acceptor_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"splice_donor_variant\"))) \"splice_donor_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"stop_gained\"))) \"stop_gained\"\n",
    "        else if (x.exists(tc => tc.contains(\"frameshift_variant\"))) \"frameshift_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"stop_lost\"))) \"stop_lost\"\n",
    "        else if (x.exists(tc => tc.contains(\"start_lost\"))) \"start_lost\"\n",
    "        else if (x.exists(tc => tc.contains(\"transcript_amplification\"))) \"transcript_amplification\"\n",
    "        else if (x.exists(tc => tc.contains(\"inframe_insertion\"))) \"inframe_insertion\"\n",
    "        else if (x.exists(tc => tc.contains(\"inframe_deletion\"))) \"inframe_deletion\"\n",
    "        else if (x.exists(tc => tc.contains(\"missense_variant\"))) \"missense_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"protein_altering_variant\"))) \"protein_altering_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"splice_region_variant\"))) \"splice_region_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"incomplete_terminal_codon_variant\"))) \"incomplete_terminal_codon_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"stop_retained_variant\"))) \"stop_retained_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"synonymous_variant\"))) \"synonymous_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"coding_sequence_variant\"))) \"coding_sequence_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"mature_miRNA_variant\"))) \"mature_miRNA_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"5_prime_UTR_variant\"))) \"5_prime_UTR_variant\" \n",
    "        else if (x.exists(tc => tc.contains(\"3_prime_UTR_variant\"))) \"3_prime_UTR_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"non_coding_transcript_exon_variant\"))) \"non_coding_transcript_exon_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"intron_variant\"))) \"intron_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"NMD_transcript_variant\"))) \"NMD_transcript_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"non_coding_transcript_variant\"))) \"non_coding_transcript_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"upstream_gene_variant\"))) \"upstream_gene_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"downstream_gene_variant\"))) \"downstream_gene_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"TFBS_ablation\"))) \"TFBS_ablation\"\n",
    "        else if (x.exists(tc => tc.contains(\"TFBS_amplification\"))) \"TFBS_amplification\"\n",
    "        else if (x.exists(tc => tc.contains(\"TF_binding_site_variant\"))) \"TF_binding_site_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"regulatory_region_ablation\"))) \"regulatory_region_ablation\"\n",
    "        else if (x.exists(tc => tc.contains(\"regulatory_region_amplification\"))) \"regulatory_region_amplification\"\n",
    "        else if (x.exists(tc => tc.contains(\"feature_elongation\"))) \"feature_elongation\"\n",
    "        else if (x.exists(tc => tc.contains(\"regulatory_region_variant\"))) \"regulatory_region_variant\"\n",
    "        else if (x.exists(tc => tc.contains(\"feature_truncation\"))) \"feature_truncation\"\n",
    "        else if (x.exists(tc => tc.contains(\"intergenic_variant\"))) \"intergenic_variant\"\n",
    "        else va.vep.most_severe_consequence\n",
    "        \"\"\")\n",
    "    .annotate_variants_expr(\n",
    "        \"\"\"\n",
    "        va.geneann.gene = \n",
    "        if (va.geneann.transcript_canonicals.exists(tc => tc.consequence_terms.toSet.contains(va.geneann.most_severe_csq))) (va.geneann.transcript_canonicals.find(tc => tc.canonical == 1 && tc.consequence_terms.toSet.contains(va.geneann.most_severe_csq)).gene_symbol)\n",
    "        else va.vep.transcript_consequences.find(tc => tc.consequence_terms.toSet.contains(va.geneann.most_severe_csq)).gene_symbol\n",
    "        \"\"\")\n",
    "    .annotate_variants_expr(\n",
    "        \"\"\"\n",
    "        va.geneann.LOFTEElof_flags = \n",
    "        if (va.geneann.transcript_canonicals.exists(tc => tc.consequence_terms.toSet.contains(va.geneann.most_severe_csq))) (va.geneann.transcript_canonicals.find(tc => tc.canonical == 1 && tc.consequence_terms.toSet.contains(va.geneann.most_severe_csq)).lof)\n",
    "        else va.vep.transcript_consequences.find(tc => tc.consequence_terms.toSet.contains(va.geneann.most_severe_csq)).lof_flags\n",
    "        \"\"\")\n",
    "    .annotate_variants_expr('va.geneann.LOFTEElof = (if (va.geneann.LOFTEElof_flags==\"HC\") 1 else 0)')\n",
    "    .annotate_variants_expr(\n",
    "        \"\"\"\n",
    "        va.geneann.damascore = (if (\"D\" ~ va.dbNSFP.SIFT_pred) 1 else 0) + (if (\"D\" ~ va.dbNSFP.PROVEAN_pred) 1 else 0) + (if (\"D\" ~ va.dbNSFP.Polyphen2_HDIV_pred) 1 else 0) + (if (\"D\" ~ va.dbNSFP.Polyphen2_HVAR_pred) 1 else 0) + (if (\"D\" ~ va.dbNSFP.LRT_pred) 1 else 0) + (if (\"[HM]\" ~ va.dbNSFP.MutationAssessor_pred) 1 else 0) + (if (\"[AD]\" ~ va.dbNSFP.MutationTaster_pred) 1 else 0)\n",
    "        \"\"\")\n",
    "    .annotate_variants_expr(\n",
    "        \"\"\"\n",
    "        va.geneann.LOF = (if (va.geneann.most_severe_csq == \"frameshift_variant\" || va.geneann.most_severe_csq == \"transcript_ablation\" || va.geneann.most_severe_csq == \"splice_acceptor_variant\" || va.geneann.most_severe_csq == \"splice_donor_variant\" || va.geneann.most_severe_csq == \"stop_gained\") 1 else 0)\n",
    "        \"\"\")\n",
    "    .annotate_variants_expr(\n",
    "        \"\"\"\n",
    "        va.geneann.missense = (if (va.geneann.most_severe_csq == \"missense_variant\" || va.geneann.most_severe_csq == \"inframe_insertion\" || va.geneann.most_severe_csq == \"inframe_deletion\") 1 else 0)\n",
    "        \"\"\")\n",
    "    .annotate_variants_expr(\n",
    "        \"\"\"\n",
    "        va.geneann.LOFdamaging = (if (va.geneann.LOF==1 || (va.geneann.missense==1 && va.geneann.damascore >= 7)) 1 else 0),\n",
    "        va.geneann.dama1 = (if ((va.geneann.missense==1 && va.geneann.damascore >= 1)) 1 else 0), \n",
    "        va.geneann.dama3 = (if ((va.geneann.missense==1 && va.geneann.damascore >= 3)) 1 else 0), \n",
    "        va.geneann.dama7 = (if ((va.geneann.missense==1 && va.geneann.damascore >= 7)) 1 else 0),\n",
    "        va.geneann.damaMPC = (if ((va.geneann.missense==1 && va.MPC >= 2)) 1 else 0),\n",
    "        va.geneann.synonymous = (if (va.geneann.most_severe_csq == \"synonymous_variant\") 1 else 0)\n",
    "        \"\"\"))\n",
    "    return(annot2vds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import a bunch of genesets. The input file has this format: the first column is the gene name. Each column is a different gene set. Each cell is 1 if the gene is in that gene set and 0 if it is not.\n",
    "We create a dictionary that looks like: `{'RAB40C': ['pLO09', 'essential_mice2', 'ALL'],'AL022328.1': []}`.\n",
    "We also read all the genes names and not in the geneset list and add those as well, with missing geneset = `[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(hc.sc)\n",
    "file=sqlContext.read.csv(root + \"all_scores_reduced.scores\",header=True, mode=\"DROPMALFORMED\",sep=\"\\t\")\n",
    "\n",
    "genenames = file.select(\"V1\").rdd.flatMap(lambda x: x).collect()\n",
    "alldf = file.collect()\n",
    "\n",
    "\n",
    "allgenesvdsK=[]\n",
    "with hadoop_read(root + 'all_gene_names.txt') as f:\n",
    "    for line in f:\n",
    "        allgenesvdsK=f.read().splitlines()\n",
    "        \n",
    "\n",
    "dictout = {}\n",
    "for l in list(allgenesvdsK):\n",
    "    if l in genenames:\n",
    "        r = alldf[genenames.index(l)]\n",
    "        ind=[k for k,i  in enumerate(r) if i==\"1\"]\n",
    "        if len(ind) > 0:\n",
    "            newdict = {l:[file.columns[i] for i in ind]}\n",
    "        else:\n",
    "            newdict = {l:[]}\n",
    "    else:\n",
    "        newdict = {l:[]}\n",
    "    dictout.update(newdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export total number genome-wide URVs per sample to use for adjustment in the model. _This output is not shared since it includes individual-level information_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## vds: input vds\n",
    "## root: where to save the output\n",
    "def export_scores_all(vds,root):\n",
    "    (vds\n",
    "    .export_samples(root + '/scores/URV_all.tsv','ID=s,COUNT=gs.filter(g => va.freq.URV).map(g => g.nNonRefAlleles).sum().toInt'))\n",
    "\n",
    "    (vds\n",
    "    .export_samples(root + '/scores/AF001_all.tsv','ID=s,COUNT=gs.filter(g => va.freq.AF001).map(g => g.nNonRefAlleles).sum().toInt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export total number of clinvar and lethal variants. Export per-sample and also per-genotype, so we can count the average number per individual. _This output is not shared since it includes individual-level information_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export_clinvar_lethal(vds,root):\n",
    "    (vds\n",
    "    .export_samples(root + '/scores/sc-clinvar-AF001-all.tsv','ID=s,COUNT=gs.filter(g => va.freq.AF001 && va.clinvar).map(g => g.nNonRefAlleles).sum().toInt'))\n",
    "\n",
    "    (vds\n",
    "    .filter_variants_expr('va.freq.AF001 && va.clinvar', keep=True)\n",
    "    .export_genotypes(root + '/scores/va-clinvar.tsv','s, v, g.nNonRefAlleles'))\n",
    "\n",
    "    (vds\n",
    "    .export_samples(root + '/scores/sc-lethal-AF001-all.tsv','ID=s,COUNT=gs.filter(g => va.freq.AF001 && va.lethal).map(g => g.nNonRefAlleles).sum().toInt'))\n",
    "\n",
    "    (vds\n",
    "    .filter_variants_expr('va.freq.AF001 && va.lethal', keep=True)\n",
    "    .export_genotypes(root + '/scores/va-lethal.tsv','s, v, g.nNonRefAlleles'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We export a large .tsv file where the first column is the sample name, the second column is the gene name and the third colum is the number of alleles. This matrix will be used in the burden-test analysis. The file is then post-processed in R to create a matrix of samples x genes. _This output is not shared since it includes individual-level information_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## vds: input vds\n",
    "## root: where to save the output\n",
    "\n",
    "def export_sample_by_gene(vds,root):\n",
    "    linreg_kt, sample_kt = (vds\n",
    "    .filter_variants_expr('va.freq.AF001 && va.geneann.LOF == 1')\n",
    "    .annotate_samples_expr('sa.pheno = pcoin(0.5)')\n",
    "    .linreg_burden(key_name='gene',\n",
    "                           variant_keys='va.geneann.gene',\n",
    "                           single_key=True,\n",
    "                           agg_expr='gs.map(g => g.gt).sum()',\n",
    "                           y='sa.pheno',\n",
    "                           covariates=[]))\n",
    "    (sample_kt.export(root + \"/genes_by_samples_AF001_LOF.tsv\"))\n",
    "    \n",
    "    linreg_kt, sample_kt = (vds\n",
    "    .filter_variants_expr('va.freq.AF001 && va.geneann.LOFdamaging == 1')\n",
    "    .annotate_variants_expr('va.id=va.geneann.gene + \"_\" + v')\n",
    "    .annotate_samples_expr('sa.pheno = pcoin(0.5)')\n",
    "    .linreg_burden(key_name='gene',\n",
    "                           variant_keys='va.id',\n",
    "                           single_key=True,\n",
    "                           agg_expr='gs.map(g => g.gt).sum()',\n",
    "                           y='sa.pheno',\n",
    "                           covariates=[]))\n",
    "    (sample_kt.export(root + \"/genes_by_samples_AF001_LOFdamaging.tsv.gz\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we export the scores for all the gene-sets. \n",
    "We  considered 6 different classes of variants: Loss of function, loss of function + damaging, damaging (1 algorithm), damaging (3 algorithms), damaging (7 algorithms), damaging (as defined by badness score >= 2) synonymous.\n",
    "\n",
    "We are exporting different scores:\n",
    "- All heterozygous and homozygous mutations (we also export genotype-level data for figure 1)\n",
    "- Only homozygous mutations\n",
    "- Only indels\n",
    "- Only SNPs\n",
    "- No C->T or G->A\n",
    "- Only high-quality variants as defined in step1 of this analysis and only regions well covered by all captures kit\n",
    "\n",
    "_This output is not shared since it includes individual-level information_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def export_geneset_by_sample(vds,filter_expr,what_sum,out_tsv,genescores_dict):\n",
    "    vdsT1=(vds\n",
    "        .annotate_global('global.staged',genescores_dict,TDict(TString(),TArray(TString()))))\n",
    "    vdsT2=(vdsT1.\n",
    "         annotate_variants_expr('va.geneSets = global.staged[va.geneann.gene]'))\n",
    "\n",
    "    linreg_kt, sample_kt = (vdsT2\n",
    "        .filter_variants_expr(filter_expr, keep=True)\n",
    "        .annotate_samples_expr('sa.pheno = pcoin(0.5)')\n",
    "        .linreg_burden(key_name='geneSets',\n",
    "                           variant_keys='va.geneSets',\n",
    "                           single_key=False,\n",
    "                           agg_expr='%s' % (what_sum),\n",
    "                           y='sa.pheno',\n",
    "                           covariates=[]))\n",
    "    sample_kt.export(out_tsv)\n",
    "\n",
    "    \n",
    "def gen_scores_ext(vds,genescores_dict,root_dir,DBS=False):\n",
    "    freqfilter=['URV','AF001']\n",
    "    dfilter=['LOF','LOFdamaging','dama1','dama3','dama7','damaMPC','synonymous']\n",
    "    \n",
    "    \n",
    "    high_qual_variants = (hc.import_table(root_dir + '/high_quality_for_age_analysis.tsv',no_header=True, impute=True)\n",
    "        .annotate('variant = f0')\n",
    "        .key_by('variant'))\n",
    "    \n",
    "    alllist_ext = list(itertools.product(freqfilter, dfilter))\n",
    " \n",
    "    for x in alllist_ext:\n",
    "        print(x)\n",
    "        filterEX='va.freq.%s && va.geneann.%s == 1' % (x[0],x[1])\n",
    "        export_geneset_by_sample(vds=vds,\n",
    "                                 filter_expr=filterEX,\n",
    "                                 what_sum='gs.map(g => g.nNonRefAlleles).sum()',\n",
    "                                 out_tsv=root_dir + '/scores/sc-%s-%s-ALL.tsv' % (x[0],x[1]),\n",
    "                                 genescores_dict=genescores_dict)\n",
    "\n",
    "        filterEX='va.freq.%s && va.geneann.%s == 1' % (x[0],x[1])\n",
    "        export_geneset_by_sample(vds=vds,\n",
    "                                 filter_expr=filterEX,\n",
    "                                 what_sum='gs.filter(g => g.isHomVar).count()',\n",
    "                                 out_tsv=root_dir + '/scores/sc-%s-%s-HOM.tsv' % (x[0],x[1]),\n",
    "                                 genescores_dict=genescores_dict)\n",
    "         \n",
    "        if DBS == False:\n",
    "            filterEX= 'va.freq.%s && va.geneann.%s == 1' % (x[0],x[1])\n",
    "            vdsT2 = (vds\n",
    "                     .filter_variants_table(high_qual_intervals)\n",
    "                     .filter_variants_table(high_qual_variants))\n",
    "            export_geneset_by_sample(vds=vdsT2,\n",
    "                                     filter_expr=filterEX,\n",
    "                                     what_sum='gs.map(g => g.nNonRefAlleles).sum()',\n",
    "                                     out_tsv=root_dir + '/scores/sc-%s-%s-HIQFORAGE.tsv' % (x[0],x[1]),\n",
    "                                     genescores_dict=genescores_dict)  \n",
    "            \n",
    "            filterEX='v.altAllele.isSNP && va.freq.%s && va.geneann.%s == 1' % (x[0],x[1])\n",
    "            export_geneset_by_sample(vds=vds,\n",
    "                                     filter_expr=filterEX,\n",
    "                                     what_sum='gs.map(g => g.nNonRefAlleles).sum()',\n",
    "                                     out_tsv=root_dir + '/scores/sc-%s-%s-SNP.tsv' % (x[0],x[1]),\n",
    "                                     genescores_dict=genescores_dict)\n",
    "\n",
    "            filterEX='''\n",
    "                        va.freq.%s && va.geneann.%s == 1 && \n",
    "                        v.altAllele.isSNP && ((v.altAllele.ref!=\"C\" &&  v.altAllele.alt!=\"T\") && \n",
    "                        (v.altAllele.ref!=\"G\" && v.altAllele.alt!=\"A\"))\n",
    "                        ''' % (x[0],x[1])\n",
    "            export_geneset_by_sample(vds=vds,\n",
    "                                     filter_expr=filterEX,\n",
    "                                     what_sum='gs.map(g => g.nNonRefAlleles).sum()',\n",
    "                                     out_tsv=root_dir + '/scores/sc-%s-%s-SNPNOCTGA.tsv' % (x[0],x[1]),\n",
    "                                     genescores_dict=genescores_dict)\n",
    "\n",
    "            if x[1] in ['LOF','LOFdamaging','synonymous']:\n",
    "                \n",
    "                filterEX='v.altAllele.isIndel && va.freq.%s && va.geneann.%s == 1' % (x[0],x[1])\n",
    "                export_geneset_by_sample(vds=vds,\n",
    "                                         filter_expr=filterEX,\n",
    "                                         what_sum='gs.map(g => g.nNonRefAlleles).sum()',\n",
    "                                         out_tsv=root_dir + '/scores/sc-%s-%s-INDEL.tsv' % (x[0],x[1]),\n",
    "                                         genescores_dict=genescores_dict)         \n",
    "            \n",
    "            \n",
    "        if x[1] in ['synonymous','LOF']:\n",
    "            \n",
    "            vdsT1=(vds\n",
    "                   .filter_variants_expr('va.freq.%s && va.geneann.%s == 1' % (x[0],x[1]), keep=True)\n",
    "                   .annotate_global('global.staged',dictout,TDict(TString(),TArray(TString())))\n",
    "                   .annotate_variants_expr('va.geneSets = global.staged[va.geneann.gene]'))\n",
    "\n",
    "            (vdsT1\n",
    "             .filter_variants_expr('va.geneSets.toSet().contains(\"pHI09\")')\n",
    "             .export_genotypes(root_dir + '/scores/va-pHI09-%s-%s.tsv' % (x[0],x[1]),'s, v, g.nNonRefAlleles'))\n",
    "\n",
    "            (vdsT1\n",
    "             .filter_variants_expr('va.geneSets.toSet().contains(\"ALL\")')\n",
    "             .export_genotypes(root_dir + '/scores/va-ALL-%s-%s.tsv' % (x[0],x[1]),'s, v, g.nNonRefAlleles'))\n",
    "\n",
    "            (vdsT1\n",
    "             .filter_variants_expr('va.geneSets.toSet().contains(\"pLO01\")')\n",
    "             .export_genotypes(root_dir + '/scores/va-pLO01-%s-%s.tsv' % (x[0],x[1]),'s, v, g.nNonRefAlleles'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Linear or logistic association analysis between scores and phenotypes \n",
    "\n",
    "The function below tests the association between each score and the phenotypes, adjusting for covariates. Code is in R.\n",
    "\n",
    "We first define the phenotype file, the covariates and the outcomes as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The example below is for the swedish-schizoprenia cohort, similar approach is used for all\n",
    "## the cohorts/ethnicities in the study\n",
    "\n",
    "path <- root\n",
    "phenotypdata <- read.csv(paste0(path,\"phenotypes.csv\"), stringsAsFactors=F)\n",
    "covariates <- c(\"age\",\"sex\",\"PC1\",\"PC2\",\"PC3\",\"PC4\",\"PC5\",\"PC6\",\"PC7\",\"PC8\",\"PC9\",\"PC10\")\n",
    "suffix <- c(\"sweden/NO_ADJ_SCZ\")\n",
    "pheno <- c(\"scz\",\"BMI\",\"SYST\",\"DIAS\",\"LNGD\",\"LNGD_RAW\")\n",
    "type <- c(\"D\",\"C\",\"C\",\"C\",\"C\",\"C\") # C=continous,D=dichotomous\n",
    "POP <- c(\"nfe\") # If POP is in your phenotype file, this keeps only that POP    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URV_score <- read.table(paste0(path,\"scores/URV_all.tsv\"), stringsAsFactor=F, header=T)\n",
    "AF001_score <- read.table(paste0(path,\"scores/AF001_all.tsv\"), stringsAsFactor=F, header=T)\n",
    "DOUBLEURV_score <- read.table(paste0(path,\"scores/DOUBLEURV_all.tsv\"), stringsAsFactor=F, header=T)\n",
    "\n",
    "#### ALL SCORES AND VARIANTS ###\n",
    "allscores <- list.files(paste0(path,\"scores/\"), pattern=\"^sc-*\")\n",
    "\n",
    "## We exclude these scores because only used in the sensitivity analysis the age-analysis ###\n",
    "allscores <- allscores[grepl(\"LOF|LOFdamaging|dama1|dama3|dama7|synonymous\",allscores) & !grepl(\"SNP|INDEL|SNPNOCTGA|HIQFORAGE|HOM\",allscores)]\n",
    "\n",
    "\n",
    "MATSCORE <- matrix(,ncol=length(allscores), nrow=nrow(URV_score))\n",
    "GENSETL <- NULL\n",
    "FREQL <- NULL\n",
    "DFILTERL <- NULL\n",
    "VARTYPE <- NULL\n",
    "for (nscore in 1:length(allscores))\n",
    "{\n",
    "\tscore <- read.table(paste0(path,\"scores/\",allscores[nscore]), stringsAsFactor=F, header=T, sep=\"\\t\")\n",
    "\n",
    "\tch <- strsplit(gsub(\".tsv\",\"\",allscores[nscore]),\"-\")[[1]]\n",
    "\tGENSETL <- c(GENSETL,ch[2])\n",
    "\tFREQL <- c(FREQL,ch[3])\n",
    "\n",
    "\tif (length(ch)==5)\n",
    "\t{\n",
    "\t\tDFILTERL <- c(DFILTERL,paste0(ch[4],\"HOM\"))\n",
    "\t}else\n",
    "\t{\n",
    "\t\tDFILTERL <- c(DFILTERL,ch[4])\n",
    "\t}\n",
    "\n",
    "\tMATSCORE[,nscore] <- score$COUNT\n",
    "}\n",
    "\n",
    "\n",
    "## ADD SYNOSCORE (which will be at the end)\n",
    "MATSCOREM <- data.frame(ID=URV_score$ID,MATSCORE,S_URV=URV_score[,2], S_AF001=AF001_score[,2], S_SING=SING_score[,2], S_DOUBLEURV=DOUBLEURV_score[,2],stringsAsFactors=F)\n",
    "\n",
    "### MERGE PHENOTYPE WITH ALL THE SCORES, BUT THE SCORE WILL BE IN THE FRONT ###\n",
    "\n",
    "mergeddata <- merge(MATSCOREM,phenotypdata,by.x=\"ID\", by.y=\"ID\")\n",
    "\n",
    "### SELECT ONLY SPECIFIED POPS ####\n",
    "\n",
    "mergeddata <- mergeddata[mergeddata$POP %in% POP,]\n",
    "\n",
    "print(paste0(\"N before exclusions:\",nrow(mergeddata)))\n",
    "\n",
    "### EXCLUDE INDIVIDUALS WITH median(x) +/- 4 MADs number of SYNONYMOUS SINGLETONS ###\n",
    "if (mad(mergeddata$S_URV) == 0 )\n",
    "{\n",
    "\tmergeddata <- mergeddata[(mergeddata$S_URV < median(mergeddata$S_URV) + 4*mad(mergeddata$S_URV)) & (mergeddata$S_URV > median(mergeddata$S_URV) - 4*mad(mergeddata$S_URV)),]\n",
    "\n",
    "\tprint(paste0(\"N after exclusions:\",nrow(mergeddata)))\n",
    "} else\n",
    "{\n",
    "\tmergeddata <- mergeddata[(mergeddata$S_URV < median(mergeddata$S_URV) + 4*sd(mergeddata$S_URV)) & (mergeddata$S_URV > median(mergeddata$S_URV) - 4*sd(mergeddata$S_URV)),]\n",
    "\n",
    "\tprint(paste0(\"N after exclusions:\",nrow(mergeddata)))\n",
    "}\n",
    "\n",
    "phenotypdataX <- mergeddata[,colnames(mergeddata) %in% c(colnames(phenotypdata),\"S_URV\",\"S_AF001\",\"S_SING\",\"S_DOUBLEURV\")]\n",
    "\n",
    "\n",
    "lhciC <- function(x)\n",
    "{\n",
    "  \n",
    "coSYNO <- coef(x)[grepl(\"^S_\",names(coef(x)))]\n",
    "seSYNO <- coef(summary(x))[grepl(\"^S_\",rownames(coef(summary(x)))),2]\n",
    "pSYNO <- coef(summary(x))[grepl(\"^S_\",rownames(coef(summary(x)))),4]\n",
    "\n",
    "namex <- names(coef(x))[grepl(\"^X\",names(coef(x)))]\n",
    "\n",
    "if(is.na(coef(x)[grepl(\"^X\",names(coef(x)))]))\n",
    "\n",
    "{\n",
    "\tcoX <- NA\n",
    "\tpX <- NA\n",
    "\tseX <- NA\n",
    "\thiX <- NA\n",
    "\tliX <- NA\n",
    "}\n",
    "else\n",
    "{\n",
    "\tcoX <- coef(x)[grepl(\"^X\",names(coef(x)))]\n",
    "\tpX <- coef(summary(x))[grepl(\"^X\",rownames(coef(summary(x)))),4]\n",
    "\tseX <- coef(summary(x))[grepl(\"^X\",rownames(coef(summary(x)))),2]\n",
    "\thiX <- coX + 1.96 * seX\n",
    "\tliX <- coX - 1.96 * seX\n",
    "}\n",
    "\n",
    "if(x$family$family==\"binomial\")\n",
    "{\n",
    "\tN <- table(x$y)\n",
    "\tTOTVAR <- c(sum(x$model[x$y==0,namex]),sum(x$model[x$y==1,namex]))\n",
    "}\n",
    "\n",
    "else\n",
    "{\n",
    "\tN <- length(x$y)\n",
    "\tTOTVAR <- sum(x$model[,namex])\n",
    "}\n",
    "\n",
    "return(c(coSYNO,seSYNO,pSYNO,coX,pX,seX,hiX,liX,N,TOTVAR))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "if (\"C\" %in% type)\n",
    "{\n",
    "\tphenosC <- pheno[type==\"C\"]\n",
    "\n",
    "\tprint(paste0(\"Running analysis on continuous phenotypes: \",paste(phenosC, collapse=\",\")))\n",
    "\n",
    "\tRESCOREC <- NULL\n",
    "\tRESVARC <- NULL\n",
    "\tRESVARCG <- NULL\n",
    "\tfor (p in phenosC)\n",
    "\t{\n",
    "\n",
    "\t\tif (\"COHORT\" %in% covariates & nlevels(factor(mergeddata$COHORT[!is.na(mergeddata[[p]])]))==1)\n",
    "\t\t{covariatesnew <- covariates[!covariates %in% \"COHORT\"]} else {covariatesnew <- covariates}\n",
    "\n",
    "\t\tfbase <- as.formula(paste0(p,\"~\",paste(covariatesnew,collapse=\"+\"),\" + S_AF001\"))\n",
    "\t\tprint(p)\n",
    "\t\t\n",
    "\n",
    "\t\tfor (nscore in 1:ncol(MATSCORE))\n",
    "\t\t{\n",
    "\n",
    "\t\t    f <- as.formula(paste0(p,\"~\",paste(covariatesnew,collapse=\"+\"),\" + S_\",FREQL[nscore],\"+ X\",nscore))\n",
    "\t\t    mod <- glm(f, data=mergeddata)\n",
    "\t\t    csm <- coef(summary(mod))\n",
    "\t\t    RESCOREC <- rbind(RESCOREC,c(p,GENSETL[nscore],FREQL[nscore],DFILTERL[nscore],lhciC(mod)))\n",
    "\t\t}\n",
    "\n",
    "\t\tcolnames(RESCOREC) <- c(\"pheno\",\"geneset_name\",\"freq_thsld\",\"dfilter\",\"beta_syno\",\"se_syno\",\"p_syno\",\"beta_x\",\"p_x\",\"se_x\",\"hi_x\",\"li_x\",\"N\",\"TOTVAR\")\n",
    "\n",
    "\t}\n",
    "\n",
    "write.table(RESCOREC,file=paste0(path,suffix,\"_CONT_BURDEN.txt\"), quote=F, row.names=F, sep=\"\\t\")\n",
    "print(p)\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "if (\"D\" %in% type)\n",
    "{\n",
    "\tphenosD <- pheno[type==\"D\"]\n",
    "\n",
    "\tprint(paste0(\"Running analysis on dichotomus phenotypes: \",paste(phenosD, collapse=\",\")))\n",
    "\n",
    "\tRESCORED <- NULL\n",
    "\tRESVARD <- NULL\n",
    "\tRESVARDG <- NULL\n",
    "\tfor (p in phenosD)\n",
    "\t{\n",
    "\n",
    "\t\t\n",
    "\t\tif (\"COHORT\" %in% covariates & nlevels(factor(mergeddata$COHORT[!is.na(mergeddata[[p]])]))==1) {covariatesnew <- covariates[!covariates %in% \"COHORT\"]} else {covariatesnew <- covariates}\n",
    "\n",
    "\t\tfbase <- as.formula(paste0(p,\"~\",paste(covariatesnew,collapse=\"+\"),\" + S_AF001\"))\n",
    "\t\tprint(p)\n",
    "\n",
    "\t\tfor (nscore in 1:ncol(MATSCORE))\n",
    "\t\t{\n",
    "\n",
    "\t\t   \tf <- as.formula(paste0(p,\"~\",paste(covariatesnew,collapse=\"+\"),\" + S_\",FREQL[nscore],\"+ X\",nscore))\n",
    "\t\t    mod <- glm(f, data=mergeddata,family=binomial())\n",
    "\t\t    csm <- coef(summary(mod))\n",
    "\t\t    RESCORED <- rbind(RESCORED,c(p,GENSETL[nscore],FREQL[nscore],DFILTERL[nscore],lhciC(mod)))\n",
    "\t\t}\n",
    "\n",
    "\t\tcolnames(RESCORED) <- c(\"pheno\",\"geneset_name\",\"freq_thsld\",\"dfilter\",\"beta_syno\",\"se_syno\",\"p_syno\",\"beta_x\",\"p_x\",\"se_x\",\"hi_x\",\"li_x\",\"N_CNTL\",\"N_CASES\",\"TOTVAR_CNTL\",\"TOTVAR_CASES\")\n",
    "\n",
    "\t}\n",
    "\n",
    "write.table(RESCORED,file=paste0(path,suffix,\"_DICOT_BURDEN.txt\"), quote=F, row.names=F, sep=\"\\t\")\n",
    "print(p)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 4: SKAT Burden-test for association between scores and phenotypes\n",
    "\n",
    "We test the association between each score and the phenotypes using burden, SKAT or SKAT-O test. The impute is the same of the one used in the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(reshape2)\n",
    "library(SKAT)\n",
    "\n",
    "\n",
    "## LOAD THE TWO R MATRIX CONTAINING SAMPLE BY GENE INFORMATION ##\n",
    "load(paste0(path,\"genes_by_samples_AF001_LOF_matrix.Rdata\"))\n",
    "load(paste0(path,\"genes_by_samples_AF001_LOF_dama_matrix.Rdata\"))\n",
    "\n",
    "\n",
    "## SYSNONYMOUS FOR ADJUSTMENT ##\n",
    "URV_score <- read.table(paste0(path,\"scores/URV_all.tsv\"), stringsAsFactor=F, header=T)\n",
    "AF001_score <- read.table(paste0(path,\"scores/AF001_all.tsv\"), stringsAsFactor=F, header=T)\n",
    "DOUBLEURV_score <- read.table(paste0(path,\"scores/DOUBLEURV_all.tsv\"), stringsAsFactor=F, header=T)\n",
    "\n",
    "\n",
    "## This folder contains all the gene-sets to be tested, \n",
    "## each file is simply a .txt file containing the gene names for that specific geneset \n",
    "\n",
    "allgenefiles <- list.files(\"dir_with_genelists_for_burden\")\n",
    "\n",
    "\n",
    "## ADD SYNOSCORE (which will be at the end)\n",
    "MATSCOREM <- data.frame(ID=URV_score$ID,MATSCORE,S_URV=URV_score[,2], S_AF001=AF001_score[,2], S_SING=SING_score[,2], S_DOUBLEURV=DOUBLEURV_score[,2],stringsAsFactors=F)\n",
    "\n",
    "### MERGE PHENOTYPE WITH ALL THE SCORES, BUT THE SCORE WILL BE IN THE FRONT ###\n",
    "\n",
    "mergeddata <- merge(MATSCOREM,phenotypdata,by.x=\"ID\", by.y=\"ID\")\n",
    "\n",
    "### SELECT ONLY SPECIFIED POPS ####\n",
    "\n",
    "mergeddata <- mergeddata[mergeddata$POP %in% POP,]\n",
    "\n",
    "print(paste0(\"N before exclusions:\",nrow(mergeddata)))\n",
    "\n",
    "### EXCLUDE INDIVIDUALS WITH median(x) +/- 4 MADs number of SYNONYMOUS SINGLETONS ###\n",
    "if (mad(mergeddata$S_URVEXACV2EHR) == 0 )\n",
    "{\n",
    "\tmergeddata <- mergeddata[(mergeddata$S_URVEXACV2EHR < median(mergeddata$S_URVEXACV2EHR) + 4*mad(mergeddata$S_URVEXACV2EHR)) & (mergeddata$S_URVEXACV2EHR > median(mergeddata$S_URVEXACV2EHR) - 4*mad(mergeddata$S_URVEXACV2EHR)),]\n",
    "\n",
    "\tprint(paste0(\"N after exclusions:\",nrow(mergeddata)))\n",
    "} else\n",
    "{\n",
    "\tmergeddata <- mergeddata[(mergeddata$S_URVEXACV2EHR < median(mergeddata$S_URVEXACV2EHR) + 4*sd(mergeddata$S_URVEXACV2EHR)) & (mergeddata$S_URVEXACV2EHR > median(mergeddata$S_URVEXACV2EHR) - 4*sd(mergeddata$S_URVEXACV2EHR)),]\n",
    "\n",
    "\tprint(paste0(\"N after exclusions:\",nrow(mergeddata)))\n",
    "}\n",
    "\n",
    "phenotypdataX <- mergeddata[,colnames(mergeddata) %in% c(colnames(phenotypdata),\"S_URVEXACV2EHR\",\"S_AF001\",\"S_SING\",\"S_DOUBLEEXACV2EHR\",\"S_AF01\")]\n",
    "\n",
    "\n",
    "\n",
    "lhciC <- function(x)\n",
    "{\n",
    "  \n",
    "coSYNO <- coef(x)[grepl(\"^S_\",names(coef(x)))]\n",
    "seSYNO <- coef(summary(x))[grepl(\"^S_\",rownames(coef(summary(x)))),2]\n",
    "pSYNO <- coef(summary(x))[grepl(\"^S_\",rownames(coef(summary(x)))),4]\n",
    "\n",
    "namex <- names(coef(x))[grepl(\"^X\",names(coef(x)))]\n",
    "\n",
    "if(is.na(coef(x)[grepl(\"^X\",names(coef(x)))]))\n",
    "\n",
    "{\n",
    "\tcoX <- NA\n",
    "\tpX <- NA\n",
    "\tseX <- NA\n",
    "\thiX <- NA\n",
    "\tliX <- NA\n",
    "}\n",
    "else\n",
    "{\n",
    "\tcoX <- coef(x)[grepl(\"^X\",names(coef(x)))]\n",
    "\tpX <- coef(summary(x))[grepl(\"^X\",rownames(coef(summary(x)))),4]\n",
    "\tseX <- coef(summary(x))[grepl(\"^X\",rownames(coef(summary(x)))),2]\n",
    "\thiX <- coX + 1.96 * seX\n",
    "\tliX <- coX - 1.96 * seX\n",
    "}\n",
    "\n",
    "if(x$family$family==\"binomial\")\n",
    "{\n",
    "\tN <- table(x$y)\n",
    "\tTOTVAR <- c(sum(x$model[x$y==0,namex]),sum(x$model[x$y==1,namex]))\n",
    "}\n",
    "\n",
    "else\n",
    "{\n",
    "\tN <- length(x$y)\n",
    "\tTOTVAR <- sum(x$model[,namex])\n",
    "}\n",
    "\n",
    "return(c(coX,pX,seX,N,TOTVAR))\n",
    "}\n",
    "\n",
    "\n",
    "##### CONTINUOUS OUTCOME ######\n",
    "\n",
    "if (\"C\" %in% type)\n",
    "{\n",
    "\tphenosC <- pheno[type==\"C\"]\n",
    "\n",
    "\tprint(paste0(\"Running analysis on continuous phenotypes: \",paste(phenosC, collapse=\",\")))\n",
    "\n",
    "\n",
    "\tRESVARCG <- NULL\n",
    "\tfor (p in phenosC)\n",
    "\t{\n",
    "\n",
    "\t\tif (\"COHORT\" %in% covariates & nlevels(factor(mergeddata$COHORT[!is.na(mergeddata[[p]])]))==1)\n",
    "\t\t{covariatesnew <- covariates[!covariates %in% \"COHORT\"]} else {covariatesnew <- covariates}\n",
    "\n",
    "\t\tfbase <- as.formula(paste0(p,\"~\",paste(covariatesnew,collapse=\"+\"),\" + S_AF001\"))\n",
    "\t\tprint(p)\n",
    "\t\t\n",
    "\n",
    "\n",
    "\t\tphenotypdataS <- phenotypdataX[complete.cases(phenotypdataX[,all.vars(fbase)]),]\n",
    "\n",
    "\t\tif (\"COHORT\" %in% covariates)\n",
    "\t\t\t\t{phenotypdataS$COHORT <- factor(phenotypdataS$COHORT)}\n",
    "\n",
    "\t\texac_gbS <- gene_sample_AF001_LOF_mat[gene_sample_AF001_LOF_mat$Sample %in% phenotypdataS$ID,]\n",
    "\t\texac_gbSdama <- gene_sample_AF001_LOF_dama_mat[gene_sample_AF001_LOF_dama_mat$Sample %in% phenotypdataS$ID,]\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\tfor (ngene in 1:length(allgenefiles))\n",
    "\t\t{\n",
    "\n",
    "\t\tif (file.size(paste0(\"dir_with_genelists_for_burden\",allgenefiles[ngene])) >0 )\n",
    "\t   \t\t{\n",
    "\t\t\t\tdgene <- read.table(paste0(\"dir_with_genelists_for_burden\",allgenefiles[ngene]), stringsAsFactor=F, header=F, sep=\"\\t\")\n",
    "\n",
    "\t\t\t\tRESTEMP1 <- NULL\n",
    "\t\t\t\tRESTEMP2 <- NULL\n",
    "\n",
    "\t\t\t\texac_gbT <- exac_gbS[,colnames(exac_gbS) %in% dgene$V1,drop=FALSE]\n",
    "\t\t\t\texac_gbTdama <- exac_gbSdama[,colnames(exac_gbSdama) %in% dgene$V1,drop=FALSE]\n",
    "\n",
    "\t\t\t\tif (nrow(exac_gbT) > 3 & ncol(exac_gbT[,colSums(exac_gbT)!=0,drop=FALSE]) > 1 )\n",
    "\t\t\t   \t{\n",
    "\n",
    "\t\t\t   \t\t######## LOF ############\n",
    "\t\t\t   \t\t#########################\n",
    "\n",
    "\t\t\t   \t\n",
    "\t\t\t\t\tgenosm <- exac_gbT[order(match(exac_gbS$Sample,phenotypdataS$ID)),colSums(exac_gbT)!=0,drop=FALSE]\n",
    "\t\t\t\t\tgenosm <- data.matrix(genosm)\n",
    "\t\t\t\t\tXBURDEN <- rowSums(genosm)\n",
    "\t\t\t\t\tfbaseused <- update(fbase, ~ . + XBURDEN)\n",
    "\n",
    "\t\t\t\t\t### Linear association (Burden) ###\n",
    "\t\t    \t\tmod <- glm(fbaseused, data=phenotypdataS)\n",
    "\t\t   \t\t\tcsm <- coef(summary(mod))\n",
    "\t\t  \t\t\treslin <- lhciC(mod)\n",
    "\n",
    "\n",
    "\t\t  \t\t\t#### SKAT-O TEST #####\n",
    "\t\t\t\t\tobj <- SKAT_Null_Model(fbase,out_type=\"C\",n.Resampling=0, type.Resampling=\"bootstrap\", Adjustment=FALSE, data=phenotypdataS)\n",
    "\t\t\t\t\tskmod <- tryCatch({SKAT(genosm,obj,kernel=\"linear\",method=\"optimal.adj\", impute.method=\"bestguess\")}, error = function(err) {\"SKAT_ERROR\"})\n",
    "\t\t\t\t\tif (skmod[1]!=\"SKAT_ERROR\")\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tif(!is.null(skmod$param$rho_est))\n",
    "\t\t\t\t\t\t{pvalSKATO <- skmod$p.value\n",
    "\t\t\t\t\t\trhoSKATO <- skmod$param$rho_est[1]\n",
    "\t\t\t\t\t\tpvalSKAT <- skmod$param$p.val.each[1]}\n",
    "\t\t\t\t\t\telse\n",
    "\t\t\t\t\t\t{pvalSKATO <- skmod$p.value\n",
    "\t\t\t\t\t\trhoSKATO <- 99\n",
    "\t\t\t\t\t\tpvalSKAT <- skmod$p.value}\n",
    "\t\t\t\t\t}else\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tpvalSKATO <- NA\n",
    "\t\t\t\t\t\trhoSKATO <- NA\n",
    "\t\t\t\t\t\tpvalSKAT <- NA\n",
    "\t\t\t\t\t}\n",
    "\n",
    "\n",
    "\t\t\t\t\tRESTEMP1 <- c(p,gsub(\".txt\",\"\",allgenefiles[ngene]),\"AF001\",\"LOF\",reslin,pvalSKAT,pvalSKATO,rhoSKATO,ncol(genosm))\n",
    "\n",
    "\n",
    "\t\t\t\t\t###### DAMA + LOF ######\n",
    "\t\t\t\t\t########################\n",
    "\n",
    "\n",
    "\t\t\t\t\tgenosm <- exac_gbTdama[order(match(exac_gbSdama$Sample,phenotypdataS$ID)),colSums(exac_gbTdama)!=0,drop=FALSE]\n",
    "\t\t\t\t\tgenosm <- data.matrix(genosm)\n",
    "\t\t\t\t\tXBURDEN <- rowSums(genosm)\n",
    "\t\t\t\t\tfbaseused <- update(fbase, ~ . + XBURDEN)\n",
    "\n",
    "\t\t\t\t\t### Linear association (Burden) ###\n",
    "\t\t    \t\tmod <- glm(fbaseused, data=phenotypdataS)\n",
    "\t\t   \t\t\tcsm <- coef(summary(mod))\n",
    "\t\t  \t\t\treslin <- lhciC(mod)\n",
    "\n",
    "\n",
    "\t\t  \t\t\t#### SKAT-O TEST #####\n",
    "\t\t\t\t\tobj <- SKAT_Null_Model(fbase,out_type=\"C\",n.Resampling=0, type.Resampling=\"bootstrap\", Adjustment=FALSE, data=phenotypdataS)\n",
    "\t\t\t\t\tskmod <- tryCatch({SKAT(genosm,obj,kernel=\"linear\",method=\"optimal.adj\", impute.method=\"bestguess\")}, error = function(err) {\"SKAT_ERROR\"})\n",
    "\t\t\t\t\tif (skmod[1]!=\"SKAT_ERROR\")\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tif(!is.null(skmod$param$rho_est))\n",
    "\t\t\t\t\t\t{pvalSKATO <- skmod$p.value\n",
    "\t\t\t\t\t\trhoSKATO <- skmod$param$rho_est[1]\n",
    "\t\t\t\t\t\tpvalSKAT <- skmod$param$p.val.each[1]}\n",
    "\t\t\t\t\t\telse\n",
    "\t\t\t\t\t\t{pvalSKATO <- skmod$p.value\n",
    "\t\t\t\t\t\trhoSKATO <- 99\n",
    "\t\t\t\t\t\tpvalSKAT <- skmod$p.value}\n",
    "\t\t\t\t\t}else\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tpvalSKATO <- NA\n",
    "\t\t\t\t\t\trhoSKATO <- NA\n",
    "\t\t\t\t\t\tpvalSKAT <- NA\n",
    "\t\t\t\t\t}\n",
    "\n",
    "\t\t\t\t\tRESTEMP2 <- c(p,gsub(\".txt\",\"\",allgenefiles[ngene]),\"AF001\",\"LOFdamaging\",reslin,pvalSKAT,pvalSKATO,rhoSKATO,ncol(genosm))\n",
    "\n",
    "\t\t\t\t\tRESVARCG <- rbind(RESVARCG,rbind(RESTEMP1,RESTEMP2))\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t\t\n",
    "\t\t\t}\n",
    "\t\t}\t\t\t\n",
    "\t\tcolnames(RESVARCG) <- c(\"pheno\",\"geneset_name\",\"freq_thsld\",\"dfilter\",\"co_burden\",\"p_burden\",\"se_burden\",\"N\",\"TOTVAR\",\"p_x\",\"SKATO_PVAL\",\"rho_SKATO\",\"nmarker\")\n",
    "\t}\n",
    "\n",
    "write.table(RESVARCG,file=paste0(path,suffix,\"_CONT_SKAT.txt\"), quote=F, row.names=F, sep=\"\\t\")\n",
    "print(p)\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "##### DICHOTOMOUS OUTCOME ######\n",
    "\n",
    "if (\"D\" %in% type)\n",
    "{\n",
    "\tphenosD <- pheno[type==\"D\"]\n",
    "\n",
    "\tprint(paste0(\"Running analysis on dichotomus phenotypes: \",paste(phenosD, collapse=\",\")))\n",
    "\n",
    "\n",
    "\tRESVARDG <- NULL\n",
    "\tfor (p in phenosD)\n",
    "\t{\n",
    "\n",
    "\t\t\n",
    "\t  if (\"COHORT\" %in% covariates & nlevels(factor(mergeddata$COHORT[!is.na(mergeddata[[p]])]))==1)\n",
    "\t\t{covariatesnew <- covariates[!covariates %in% \"COHORT\"]} else {covariatesnew <- covariates}\n",
    "\n",
    "\t\tfbase <- as.formula(paste0(p,\"~\",paste(covariatesnew,collapse=\"+\"),\" + S_AF001\"))\n",
    "\t\tprint(p)\n",
    "\t\t\n",
    "\n",
    "\n",
    "\t\tphenotypdataS <- phenotypdataX[complete.cases(phenotypdataX[,all.vars(fbase)]),]\n",
    "\n",
    "\t\tif (\"COHORT\" %in% covariates)\n",
    "\t\t\t{\n",
    "\t\t\t\tphenotypdataS$COHORT <- factor(phenotypdataS$COHORT)\n",
    "\t\t\t\tdep <- which(table(phenotypdataS$COHORT) < 2)\t\n",
    "\t\t\t\tif (length(dep)>0)\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\tlevels(phenotypdataS$COHORT)[levels(phenotypdataS$COHORT)==names(dep)] <- names(table(phenotypdataS$COHORT))[1]\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t}\n",
    "\n",
    "\t\texac_gbS <- gene_sample_AF001_LOF_mat[gene_sample_AF001_LOF_mat$Sample %in% phenotypdataS$ID,]\n",
    "\t\texac_gbSdama <- gene_sample_AF001_LOF_dama_mat[gene_sample_AF001_LOF_dama_mat$Sample %in% phenotypdataS$ID,]\n",
    "\n",
    "\n",
    "\n",
    "\t\tfor (ngene in 1:length(allgenefiles))\n",
    "\t\t{\n",
    "\n",
    "\t\tif (file.size(paste0(\"dir_with_genelists_for_burden\",allgenefiles[ngene])) >0 )\n",
    "\t   \t\t{\n",
    "\t\t\t\tdgene <- read.table(paste0(\"dir_with_genelists_for_burden\",allgenefiles[ngene]), stringsAsFactor=F, header=F, sep=\"\\t\")\n",
    "\n",
    "\n",
    "\t\t\t\tRESTEMP1 <- NULL\n",
    "\t\t\t\tRESTEMP2 <- NULL\n",
    "\n",
    "\t\t\t\texac_gbT <- exac_gbS[,colnames(exac_gbS) %in% dgene$V1,drop=FALSE]\n",
    "\t\t\t\texac_gbTdama <- exac_gbSdama[,colnames(exac_gbSdama) %in% dgene$V1,drop=FALSE]\n",
    "\n",
    "\t\t\t\tif (nrow(exac_gbT) > 3 & ncol(exac_gbT[,colSums(exac_gbT)!=0,drop=FALSE]) > 1 )\n",
    "\t\t\t   \t{\n",
    "\n",
    "\t\t\t   \t\t######## LOF ############\n",
    "\t\t\t   \t\t#########################\n",
    "\n",
    "\t\t\t\t\tgenosm <- exac_gbT[order(match(exac_gbS$Sample,phenotypdataS$ID)),colSums(exac_gbT)!=0,drop=FALSE]\n",
    "\t\t\t\t\tgenosm <- data.matrix(genosm)\n",
    "\t\t\t\t\tXBURDEN <- rowSums(genosm)\n",
    "\t\t\t\t\tfbaseused <- update(fbase, ~ . + XBURDEN)\n",
    "\n",
    "\t\t\t\t\t### Linear association (Burden) ###\n",
    "\t\t    \t\tmod <- glm(fbaseused, data=phenotypdataS, family=binomial())\n",
    "\t\t   \t\t\tcsm <- coef(summary(mod))\n",
    "\t\t  \t\t\treslin <- lhciC(mod)\n",
    "\n",
    "\n",
    "\t\t  \t\t\t#### SKAT-O TEST #####\n",
    "\n",
    "\n",
    "\t\t\t\t\tobj <- SKAT_Null_Model(fbase,out_type=\"D\",n.Resampling=0, type.Resampling=\"bootstrap\", Adjustment= FALSE, data=phenotypdataS)\n",
    "\t\t\t\t\tskmod <- tryCatch({SKATBinary(genosm,obj,kernel=\"linear\",method=\"SKATO\", impute.method=\"bestguess\")}, error = function(err) {\"SKAT_ERROR\"})\n",
    "\n",
    "\n",
    "\t\t\t\t\tif (skmod[1]!=\"SKAT_ERROR\")\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tif(!is.null(skmod$param$rho_est))\n",
    "\t\t\t\t\t\t{pvalSKATO <- skmod$p.value\n",
    "\t\t\t\t\t\trhoSKATO <- skmod$param$rho_est[1]\n",
    "\t\t\t\t\t\tpvalSKAT <- skmod$param$p.val.each[1]}\n",
    "\t\t\t\t\t\telse\n",
    "\t\t\t\t\t\t{pvalSKATO <- skmod$p.value\n",
    "\t\t\t\t\t\trhoSKATO <- 99\n",
    "\t\t\t\t\t\tpvalSKAT <- skmod$p.value}\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t\telse \n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tpvalSKATO <- NA\n",
    "\t\t\t\t\t\trhoSKATO <- NA\n",
    "\t\t\t\t\t\tpvalSKAT <- NA\n",
    "\t\t\t\t\t}\n",
    "\n",
    "\t\t\t\t\n",
    "\n",
    "\t\t\t\t\tRESTEMP1 <- c(p,gsub(\".txt\",\"\",allgenefiles[ngene]),\"AF001\",\"LOF\",reslin,pvalSKAT,pvalSKATO,rhoSKATO,ncol(genosm))\n",
    "\n",
    "\t\t\t\t\t###### DAMA + LOF ######\n",
    "\t\t\t\t\t########################\n",
    "\n",
    "\n",
    "\t\t\t\t\tgenosm <- exac_gbTdama[order(match(exac_gbSdama$Sample,phenotypdataS$ID)),colSums(exac_gbTdama)!=0,drop=FALSE]\n",
    "\t\t\t\t\tgenosm <- data.matrix(genosm)\n",
    "\t\t\t\t\tXBURDEN <- rowSums(genosm)\n",
    "\t\t\t\t\tfbaseused <- update(fbase, ~ . + XBURDEN)\n",
    "\n",
    "\t\t\t\t\t### Linear association (Burden) ###\n",
    "\t\t    \t\tmod <- glm(fbaseused, data=phenotypdataS, family=binomial())\n",
    "\t\t   \t\t\tcsm <- coef(summary(mod))\n",
    "\t\t  \t\t\treslin <- lhciC(mod)\n",
    "\n",
    "\n",
    "\t\t  \t\t\t#### SKAT-O TEST #####\n",
    "\t\t\t\t\tobj <- SKAT_Null_Model(fbase,out_type=\"D\",n.Resampling=0, type.Resampling=\"bootstrap\", Adjustment=FALSE, data=phenotypdataS)\n",
    "\t\t\t\t\tskmod <- tryCatch({SKATBinary(genosm,obj,kernel=\"linear\",method=\"SKATO\", impute.method=\"bestguess\")}, error = function(err) {\"SKAT_ERROR\"})\n",
    "\t\t\t\t\tif (skmod[1]!=\"SKAT_ERROR\")\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tif(!is.null(skmod$param$rho_est))\n",
    "\t\t\t\t\t\t{pvalSKATO <- skmod$p.value\n",
    "\t\t\t\t\t\trhoSKATO <- skmod$param$rho_est[1]\n",
    "\t\t\t\t\t\tpvalSKAT <- skmod$param$p.val.each[1]}\n",
    "\t\t\t\t\t\telse\n",
    "\t\t\t\t\t\t{pvalSKATO <- skmod$p.value\n",
    "\t\t\t\t\t\trhoSKATO <- 99\n",
    "\t\t\t\t\t\tpvalSKAT <- skmod$p.value}\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t\telse \n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tpvalSKATO <- NA\n",
    "\t\t\t\t\t\trhoSKATO <- NA\n",
    "\t\t\t\t\t\tpvalSKAT <- NA\n",
    "\t\t\t\t\t}\n",
    "\n",
    "\n",
    "\t\t\t\t\tRESTEMP2 <- c(p,gsub(\".txt\",\"\",allgenefiles[ngene]),\"AF001\",\"LOFdamaging\",reslin,pvalSKAT,pvalSKATO,rhoSKATO,ncol(genosm))\n",
    "\n",
    "\t\t\t\t\tRESVARDG <- rbind(RESVARDG,rbind(RESTEMP1,RESTEMP2))\n",
    "\t\t\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t\t\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\n",
    "\t\tcolnames(RESVARDG) <- c(\"pheno\",\"geneset_name\",\"freq_thsld\",\"dfilter\",\"co_burden\",\"p_burden\",\"se_burden\",\"N_CNTL\",\"N_CASES\",\"TOTVAR_CNTL\",\"TOTVAR_CASES\",\"p_x\",\"SKATO_PVAL\",\"rho_SKATO\",\"nmarker\")\n",
    "\t}\n",
    "\n",
    "write.table(RESVARDG,file=paste0(path,suffix,\"_DICOT_SKAT.txt\"), quote=F, row.names=F, sep=\"\\t\")\n",
    "\n",
    "print(p)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PART 5: meta-analysis of all results\n",
    "\n",
    "In this part we meta-analyze the results, for each sub-study and ethnicity within the sub-studies. Code in R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read in all the .txt files generated from the previous functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(meta)\n",
    "library(metap)\n",
    "\n",
    "#############################\n",
    "### T2D-GENES/GoT2D/SIGMA ###\n",
    "#############################\n",
    "\n",
    "\n",
    "#### BURDEN ####\n",
    "\n",
    "### Continuous outcomes ###\n",
    "diabC_afrB <- \"results_in_afr_CONT_BURDEN.txt\"\n",
    "diabC_amrB <- \"results_in_amr_CONT_BURDEN.txt\"\n",
    "diabC_easB <- \"results_in_eas_CONT_BURDEN.txt\"\n",
    "diabC_nfeB <- \"results_in_nfe_CONT_BURDEN.txt\"\n",
    "diabC_finB <- \"results_in_fin_CONT_BURDEN.txt\"\n",
    "diabC_sasB <- \"results_in_sas_CONT_BURDEN.txt\"\n",
    "\n",
    "### Adjusted by BMI ###\n",
    "diabC2_afrB <- \"results_in_afr_bmi_adj_CONT_BURDEN.txt\"\n",
    "diabC2_amrB <- \"results_in_amr_bmi_adj_CONT_BURDEN.txt\"\n",
    "diabC2_easB <- \"results_in_eas_bmi_adj_CONT_BURDEN.txt\"\n",
    "diabC2_nfeB <- \"results_in_nfe_bmi_adj_CONT_BURDEN.txt\"\n",
    "diabC2_finB <- \"results_in_fin_bmi_adj_CONT_BURDEN.txt\"\n",
    "diabC2_sasB <- \"results_in_sas_bmi_adj_CONT_BURDEN.txt\"\n",
    "\n",
    "\n",
    "### Not adjusted by age ###\n",
    "diabC_afrB <- \"results_in_afr_AGE_CONT_BURDEN.txt\"\n",
    "diabC_amrB <- \"results_in_amr_AGE_CONT_BURDEN.txt\"\n",
    "diabC_easB <- \"results_in_eas_AGE_CONT_BURDEN.txt\"\n",
    "diabC_nfeB <- \"results_in_nfe_AGE_CONT_BURDEN.txt\"\n",
    "diabC_finB <- \"results_in_fin_AGE_CONT_BURDEN.txt\"\n",
    "diabC_sasB <- \"results_in_sas_AGE_CONT_BURDEN.txt\"\n",
    "\n",
    "\n",
    "### Not adjusted by t2d ###\n",
    "diabD_afrB <- \"results_in_afr_T2D_DICOT_BURDEN.txt\"\n",
    "diabD_amrB <- \"results_in_amr_T2D_DICOT_BURDEN.txt\"\n",
    "diabD_easB <- \"results_in_eas_T2D_DICOT_BURDEN.txt\"\n",
    "diabD_nfeB <- \"results_in_nfe_T2D_DICOT_BURDEN.txt\"\n",
    "diabD_finB <- \"results_in_fin_T2D_DICOT_BURDEN.txt\"\n",
    "diabD_sasB <- \"results_in_sas_T2D_DICOT_BURDEN.txt\"\n",
    "\n",
    "\n",
    "#### SKAT ####\n",
    "\n",
    "### Continuous outcomes ###\n",
    "SdiabC_afrB <- \"results_in_afr_CONT_SKAT.txt\"\n",
    "SdiabC_amrB <- \"results_in_amr_CONT_SKAT.txt\"\n",
    "SdiabC_easB <- \"results_in_eas_CONT_SKAT.txt\"\n",
    "SdiabC_nfeB <- \"results_in_nfe_CONT_SKAT.txt\"\n",
    "SdiabC_finB <- \"results_in_fin_CONT_SKAT.txt\"\n",
    "SdiabC_sasB <- \"results_in_sas_CONT_SKAT.txt\"\n",
    "\n",
    "### Adjusted by BMI ###\n",
    "SdiabC2_afrB <- \"results_in_afr_bmi_adj_CONT_SKAT.txt\"\n",
    "SdiabC2_amrB <- \"results_in_amr_bmi_adj_CONT_SKAT.txt\"\n",
    "SdiabC2_easB <- \"results_in_eas_bmi_adj_CONT_SKAT.txt\"\n",
    "SdiabC2_nfeB <- \"results_in_nfe_bmi_adj_CONT_SKAT.txt\"\n",
    "SdiabC2_finB <- \"results_in_fin_bmi_adj_CONT_SKAT.txt\"\n",
    "SdiabC2_sasB <- \"results_in_sas_bmi_adj_CONT_SKAT.txt\"\n",
    "\n",
    "\n",
    "### Not adjusted by age ###\n",
    "SdiabC_afrB <- \"results_in_afr_AGE_CONT_SKAT.txt\"\n",
    "SdiabC_amrB <- \"results_in_amr_AGE_CONT_SKAT.txt\"\n",
    "SdiabC_easB <- \"results_in_eas_AGE_CONT_SKAT.txt\"\n",
    "SdiabC_nfeB <- \"results_in_nfe_AGE_CONT_SKAT.txt\"\n",
    "SdiabC_finB <- \"results_in_fin_AGE_CONT_SKAT.txt\"\n",
    "SdiabC_sasB <- \"results_in_sas_AGE_CONT_SKAT.txt\"\n",
    "\n",
    "\n",
    "### Not adjusted by t2d ###\n",
    "SdiabD_afrB <- \"results_in_afr_T2D_DICOT_SKAT.txt\"\n",
    "SdiabD_amrB <- \"results_in_amr_T2D_DICOT_SKAT.txt\"\n",
    "SdiabD_easB <- \"results_in_eas_T2D_DICOT_SKAT.txt\"\n",
    "SdiabD_nfeB <- \"results_in_nfe_T2D_DICOT_SKAT.txt\"\n",
    "SdiabD_finB <- \"results_in_fin_T2D_DICOT_SKAT.txt\"\n",
    "SdiabD_sasB <- \"results_in_sas_T2D_DICOT_SKAT.txt\"\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "### Swedish schizophrenia case/control ####\n",
    "###########################################\n",
    "\n",
    "#### Burden ####\n",
    "\n",
    "### Continuous outcomes ###\n",
    "sweC_nfeB <- \"results_in_nfe_ADJ_SCZ_CONT_BURDEN.txt\"\n",
    "\n",
    "### Dichotomous outcomes ###\n",
    "sweD_nfeB <- \"results_in_nfe_ADJ_SCZ_DICOT_BURDEN.txt\"\n",
    "\n",
    "### Not adjusted by schizophrenia, Continuous ###\n",
    "sweC2_nfeB <- \"results_in_nfe_NO_ADJ_SCZ_CONT_BURDEN.txt\"\n",
    "\n",
    "### Not adjusted by age ###\n",
    "sweC3_nfeB <- \"results_in_nfe_AGE_SCZ_ALL_CONT_BURDEN.txt\"\n",
    "\n",
    "### Not adjusted by schizophrenia, Dichotomous ###\n",
    "sweD2_nfeB <- \"results_in_nfe_NO_ADJ_SCZ_DICOT_BURDEN.txt\"\n",
    "\n",
    "\n",
    "\n",
    "#### SKAT ####\n",
    "\n",
    "### Continuous outcomes ###\n",
    "SsweC_nfeB <- \"results_in_nfe_ADJ_SCZ_CONT_SKAT.txt\"\n",
    "\n",
    "### Dichotomous outcomes ###\n",
    "SsweD_nfeB <- \"results_in_nfe_ADJ_SCZ_DICOT_SKAT.txt\"\n",
    "\n",
    "### Not adjusted by schizophrenia, Continuous ###\n",
    "SsweC2_nfeB <- \"results_in_nfe_NO_ADJ_SCZ_CONT_SKAT.txt\"\n",
    "\n",
    "### Not adjusted by age ###\n",
    "SsweC3_nfeB <- \"results_in_nfe_AGE_SCZ_ALL_CONT_SKAT.txt\"\n",
    "\n",
    "### Not adjusted by schizophrenia, Dichotomous ###\n",
    "SsweD2_nfeB <- \"results_in_nfe_NO_ADJ_SCZ_DICOT_SKAT.txt\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################\n",
    "### North Finland Intellectual disability ###\n",
    "#############################################\n",
    "\n",
    "nfidD_finB <- \"results_in_fin_DICOT_BURDEN.txt\"\n",
    "\n",
    "SnfidD_finB <- \"results_in_fin_DICOT_SKAT.txt\"\n",
    "\n",
    "\n",
    "#####################\n",
    "### IBD consortia ###\n",
    "#####################\n",
    "\n",
    "\n",
    "### BURDEN ###\n",
    "ibdD_nfeB <- \"results_in_nfe_DICOT_BURDEN.txt\"\n",
    "ibdD_finB <- \"results_in_fin_DICOT_BURDEN.txt\"\n",
    "ibdD_askB <- \"results_in_ask_DICOT_BURDEN.txt\"\n",
    "\n",
    "### SKAT ###\n",
    "\n",
    "SibdD_nfeB <- \"results_in_nfe_DICOT_SKAT.txt\"\n",
    "SibdD_finB <- \"results_in_fin_DICOT_SKAT.txt\"\n",
    "SibdD_askB <- \"results_in_ask_DICOT_SKAT.txt\"\n",
    "\n",
    "\n",
    "\n",
    "#############\n",
    "### Migen ###\n",
    "#############\n",
    "\n",
    "\n",
    "### Continuous outcomes ###\n",
    "migenC_afrB <- \"results_in_afr_CONT_BURDEN.txt\"\n",
    "migenC_nfeB <- \"results_in_nfe_CONT_BURDEN.txt\"\n",
    "migenC_sasB <- \"results_in_sas_CONT_BURDEN.txt\"\n",
    "\n",
    "\n",
    "### Not adjusted by age ###\n",
    "migenC2_nfeB <- \"results_in_nfe_AGE_CONT_BURDEN.txt\"\n",
    "migenC2_afrB <- \"results_in_afr_AGE_CONT_BURDEN.txt\"\n",
    "migenC2_sasB <- \"results_in_sas_AGE_CONT_BURDEN.txt\"\n",
    "\n",
    "### Dichotomous outcomes ###\n",
    "migenD_afrB <- \"results_in_afr_DICOT_BURDEN.txt\"\n",
    "migenD_nfeB <- \"results_in_nfe_DICOT_BURDEN.txt\"\n",
    "migenD_sasB <- \"results_in_sas_DICOT_BURDEN.txt\"\n",
    "\n",
    "### Not adjusted by CHD ###\n",
    "migenD2_afrB <- \"results_in_afr_NO_CHD_DICOT_BURDEN.txt\"\n",
    "migenD2_nfeB <- \"results_in_nfe_NO_CHD_DICOT_BURDEN.txt\"\n",
    "migenD2_sasB <- \"results_in_sas_NO_CHD_DICOT_BURDEN.txt\"\n",
    "\n",
    "#### SKAT ####\n",
    "\n",
    "\n",
    "### Continuous outcomes ###\n",
    "SmigenC_afrB <- \"results_in_afr_CONT_SKAT.txt\"\n",
    "SmigenC_nfeB <- \"results_in_nfe_CONT_SKAT.txt\"\n",
    "SmigenC_sasB <- \"results_in_sas_CONT_SKAT.txt\"\n",
    "\n",
    "\n",
    "### Not adjusted by age ###\n",
    "SmigenC2_nfeB <- \"results_in_nfe_AGE_CONT_SKAT.txt\"\n",
    "SmigenC2_afrB <- \"results_in_afr_AGE_CONT_SKAT.txt\"\n",
    "SmigenC2_sasB <- \"results_in_sas_AGE_CONT_SKAT.txt\"\n",
    "\n",
    "### Dichotomous outcomes ###\n",
    "SmigenD_afrB <- \"results_in_afr_DICOT_SKAT.txt\"\n",
    "SmigenD_nfeB <- \"results_in_nfe_DICOT_SKAT.txt\"\n",
    "SmigenD_sasB <- \"results_in_sas_DICOT_SKAT.txt\"\n",
    "\n",
    "### Not adjusted by CHD ###\n",
    "SmigenD2_afrB <- \"results_in_afr_NO_CHD_DICOT_SKAT.txt\"\n",
    "SmigenD2_nfeB <- \"results_in_nfe_NO_CHD_DICOT_SKAT.txt\"\n",
    "SmigenD2_sasB <- \"results_in_sas_NO_CHD_DICOT_SKAT.txt\"\n",
    "\n",
    "\n",
    "\n",
    "###############\n",
    "### Finrisk ###\n",
    "###############\n",
    "\n",
    "#### BURDEN ####\n",
    "\n",
    "### Continuous outcomes ###\n",
    "finC_finB <- \"results_in_fin_CONT_BURDEN.txt\"\n",
    "\n",
    "### Not adjusted by cohort, only for TG ###\n",
    "finC2_finB <- \"results_in_fin_NOCOHORT_CONT_BURDEN.txt\"\n",
    "\n",
    "### Adjusted by BMI ###\n",
    "finC3_finB <- \"results_in_fin_BMI_ADJ_CONT_BURDEN.txt\"\n",
    "\n",
    "### Not adjusted by age ###\n",
    "finC4_finB <- \"results_in_fin_AGE_ALL_CONT_BURDEN.txt\"\n",
    "\n",
    "\n",
    "#### SKAT ####\n",
    "\n",
    "### Continuous outcomes ###\n",
    "SfinC_finB <- \"results_in_fin_CONT_SKAT.txt\"\n",
    "\n",
    "### Not adjusted by cohort, only for TG ###\n",
    "SfinC2_finB <- \"results_in_fin_NOCOHORT_CONT_SKAT.txt\"\n",
    "\n",
    "### Adjusted by BMI ###\n",
    "SfinC3_finB <- \"results_in_fin_BMI_ADJ_CONT_SKAT.txt\"\n",
    "\n",
    "### Not adjusted by age ###\n",
    "SfinC4_finB <- \"results_in_fin_AGE_ALL_CONT_SKAT.txt\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################\n",
    "### Danish Blood Spot ####\n",
    "##########################\n",
    "\n",
    "### Continuous outcomes, Only controls ###\n",
    "dbsC_nfeB <- \"results_in_nfe_CNTL_CONT_BURDEN.txt\"\n",
    "\n",
    "### Only controls, not adjusted for age ###\n",
    "dbsC2_nfeB <- \"results_in_nfe_CNTL_AGE_CONT_BURDEN.txt\"\n",
    "\n",
    "### Age at onset within diseases ###\n",
    "dbsCAUTISM_nfeB <- \"results_in_nfe_AUTISM_CONT_BURDEN.txt\"\n",
    "dbsCADHD_nfeB <- \"results_in_nfe_ADHD_CONT_BURDEN.txt\"\n",
    "dbsCSCZ_nfeB <- \"results_in_nfe_SCZ_CONT_BURDEN.txt\"\n",
    "dbsCBP_nfeB <- \"results_in_nfe_BP_CONT_BURDEN.txt\"\n",
    "\n",
    "### Dichotomous outcomes ###\n",
    "dbsD_nfeB <- \"results_in_nfe_DICOT_BURDEN.txt\"\n",
    "\n",
    "### Dichotomous outcomes, only controls ###\n",
    "dbsD2_nfeB <-\"results_in_nfe_CNTL_DICOT_BURDEN.txt\"\n",
    "\n",
    "### Sex-specific ###\n",
    "dbsD3_nfeB <- \"results_in_nfe_FEMALE_DICOT_BURDEN.txt\"\n",
    "dbsD4_nfeB <- \"results_in_nfe_MALE_DICOT_BURDEN.txt\"\n",
    "\n",
    "\n",
    "#### SKAT ####\n",
    "\n",
    "### Continuous outcomes, Only controls ###\n",
    "SdbsC_nfeB <- \"results_in_nfe_CNTL_CONT_SKAT.txt\"\n",
    "\n",
    "### Only controls, not adjusted for age ###\n",
    "SdbsC2_nfeB <- \"results_in_nfe_CNTL_AGE_CONT_SKAT.txt\"\n",
    "\n",
    "### Age at onset within diseases ###\n",
    "SdbsCAUTISM_nfeB <- \"results_in_nfe_AUTISM_CONT_SKAT.txt\"\n",
    "SdbsCADHD_nfeB <- \"results_in_nfe_ADHD_CONT_SKAT.txt\"\n",
    "SdbsCSCZ_nfeB <- \"results_in_nfe_SCZ_CONT_SKAT.txt\"\n",
    "SdbsCBP_nfeB <- \"results_in_nfe_BP_CONT_SKAT.txt\"\n",
    "\n",
    "### Dichotomous outcomes ###\n",
    "SdbsD_nfeB <- \"results_in_nfe_DICOT_SKAT.txt\"\n",
    "\n",
    "### Dichotomous outcomes, only controls ###\n",
    "SdbsD2_nfeB <-\"results_in_nfe_CNTL_DICOT_SKAT.txt\"\n",
    "\n",
    "### Sex-specific ###\n",
    "SdbsD3_nfeB <- \"results_in_nfe_FEMALE_DICOT_SKAT.txt\"\n",
    "SdbsD4_nfeB <- \"results_in_nfe_MALE_DICOT_SKAT.txt\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############\n",
    "### METSIM ###\n",
    "##############\n",
    "\n",
    "#### BURDEN #####\n",
    "\n",
    "### Continuous outcomes ###\n",
    "metC_finB <- \"results_in_fin_CONT_BURDEN.txt\"\n",
    "\n",
    "### Not adjusted by age ###\n",
    "metC2_finB <- \"results_in_fin_AGE_CONT_BURDEN.txt\"\n",
    "\n",
    "### Adjusted by BMI ###\n",
    "metC3_finB <- \"results_in_fin_ADJ_BMI_CONT_BURDEN.txt\"\n",
    "\n",
    "#### SKAT #####\n",
    "\n",
    "### Continuous outcomes ###\n",
    "SmetC_finB <- \"results_in_fin_CONT_SKAT.txt\"\n",
    "\n",
    "### Not adjusted by age ###\n",
    "SmetC2_finB <- \"results_in_fin_AGE_CONT_SKAT.txt\"\n",
    "\n",
    "### Adjusted by BMI ###\n",
    "SmetC3_finB <- \"results_in_fin_ADJ_BMI_CONT_SKAT.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for continuous outcomes: ldl,hdl,tc,tg,sbp,dbp,height,bmi,glucose adjusted for bmi, insuline adjusted for bmi, years of education, age, birth weight adjusted for gestational age, age of diagnosis: schizophrenia, bipolar, autism, adhd.\n",
    "\n",
    "The code is quite repetitive and we need to treat each phenotype separately because unfortunately the name of the phenotypes in each dataset is not the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "METAC <- function(phenolist,phenolistS=NULL,ll)\n",
    "{\n",
    "  METARES <- NULL\n",
    "  if (is.null(phenolistS))\n",
    "  {\n",
    "    for (k in 1:nrow(ll))\n",
    "    {\n",
    "      \n",
    "      beta <- unlist(sapply(phenolist,function(x){x$beta_x[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      se <- unlist(sapply(phenolist,function(x){x$se_x[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      N <- unlist(sapply(phenolist,function(x){x$N[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      NVAR <- unlist(sapply(phenolist,function(x){x$TOTVAR[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      beta_syno <- unlist(sapply(phenolist,function(x){x$beta_syno[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      se_syno <- unlist(sapply(phenolist,function(x){x$se_syno[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      if (length(beta) > 0)\n",
    "      {\n",
    "        mod <- metagen(beta,se,studlab=seq(1:length(beta)))\n",
    "        modsyno <- metagen(beta_syno,se_syno,studlab=seq(1:length(beta_syno)))\n",
    "        METAFIN <- c(as.character(ll[k,1]),as.character(ll[k,2]),as.character(ll[k,3]),sum(as.numeric(N)),sum(as.numeric(NVAR)),mod$TE.fixed,mod$seTE.fixed,mod$lower.fixed,mod$upper.fixed,mod$pval.fixed,modsyno$TE.fixed,modsyno$seTE.fixed,modsyno$lower.fixed,modsyno$upper.fixed,modsyno$pval.fixed,NA,NA,NA,NA,NA,NA,NA,NA)\n",
    "\n",
    "        METARES <- rbind(METARES,METAFIN)\n",
    "\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  else\n",
    "  {\n",
    "    for (k in 1:nrow(ll))\n",
    "    {\n",
    "\n",
    "      METAFIN <- NULL\n",
    "      beta <- unlist(sapply(phenolist,function(x){x$beta_x[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      se <- unlist(sapply(phenolist,function(x){x$se_x[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      N <- unlist(sapply(phenolist,function(x){x$N[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      NVAR <- unlist(sapply(phenolist,function(x){x$TOTVAR[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      beta_syno <- unlist(sapply(phenolist,function(x){x$beta_syno[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      se_syno <- unlist(sapply(phenolist,function(x){x$se_syno[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      pSKAT <- unlist(sapply(phenolistS,function(x){x$p_x[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      pSKATO <- unlist(sapply(phenolistS,function(x){x$SKATO_PVAL[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      betaBURDEN <- unlist(sapply(phenolistS,function(x){x$co_burden[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      seBURDEN <- unlist(sapply(phenolistS,function(x){x$se_burden[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "\n",
    "      SKATN <- unlist(sapply(phenolistS,function(x){x$nmarker[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      pSKAT[pSKAT==0] <- 1e-16\n",
    "      pSKATO[pSKATO==0] <- 1e-16\n",
    "      pSKAT[pSKAT>1] <- NA\n",
    "      pSKATO[pSKATO>1] <- NA\n",
    "\n",
    "      pSKAT <- pSKAT[!is.na(pSKAT)]\n",
    "      pSKATO <- pSKATO[!is.na(pSKATO)]\n",
    "\n",
    "      if (length(beta) > 0 & length(pSKAT) == 0 & length(pSKATO) == 0)\n",
    "      {\n",
    "        mod <- metagen(beta,se,studlab=seq(1:length(beta)))\n",
    "        modsyno <- metagen(beta_syno,se_syno,studlab=seq(1:length(beta_syno)))\n",
    "\n",
    "        METAFIN <- c(as.character(ll[k,1]),as.character(ll[k,2]),as.character(ll[k,3]),sum(as.numeric(N)),sum(as.numeric(NVAR)),mod$TE.fixed,mod$seTE.fixed,mod$lower.fixed,mod$upper.fixed,mod$pval.fixed,modsyno$TE.fixed,modsyno$seTE.fixed,modsyno$lower.fixed,modsyno$upper.fixed,modsyno$pval.fixed,NA,NA,NA,NA,NA,NA,NA,NA)\n",
    "\n",
    "      }\n",
    "      if (length(beta) > 0 & length(pSKAT) > 0 & length(pSKATO) > 0)\n",
    "      {\n",
    "        mod <- metagen(beta,se,studlab=seq(1:length(beta)))\n",
    "        modsyno <- metagen(beta_syno,se_syno,studlab=seq(1:length(beta_syno)))\n",
    "        modburden <- metagen(betaBURDEN,seBURDEN,studlab=seq(1:length(betaBURDEN)))\n",
    "\n",
    "\n",
    "        if (length(pSKAT) > 1)\n",
    "        {modskat <- sumlog(pSKAT)$p}\n",
    "        else\n",
    "        {modskat <- pSKAT}\n",
    "\n",
    "        if (length(pSKATO) > 1)\n",
    "        {modskatO <- sumlog(pSKATO)$p}\n",
    "        else\n",
    "        {modskatO <- pSKATO}\n",
    "        \n",
    "\n",
    "        METAFIN <- c(as.character(ll[k,1]),as.character(ll[k,2]),as.character(ll[k,3]),sum(as.numeric(N)),sum(as.numeric(NVAR)),mod$TE.fixed,mod$seTE.fixed,mod$lower.fixed,mod$upper.fixed,mod$pval.fixed,modsyno$TE.fixed,modsyno$seTE.fixed,modsyno$lower.fixed,modsyno$upper.fixed,modsyno$pval.fixed,modskat,modskatO,modburden$TE.fixed,modburden$seTE.fixed,modburden$pval.fixed,max(as.numeric(SKATN)),paste0(length(pSKAT),\"/\",length(phenolistS)),paste0(length(pSKATO),\"/\",length(phenolistS)))\n",
    "\n",
    "      }\n",
    "\n",
    "      if (length(beta) > 0 & length(pSKAT) > 0 & length(pSKATO) == 0)\n",
    "      {\n",
    "        mod <- metagen(beta,se,studlab=seq(1:length(beta)))\n",
    "        modsyno <- metagen(beta_syno,se_syno,studlab=seq(1:length(beta_syno)))\n",
    "        modburden <- metagen(betaBURDEN,seBURDEN,studlab=seq(1:length(betaBURDEN)))\n",
    "\n",
    "\n",
    "        if (length(pSKAT) > 1)\n",
    "        {modskat <- sumlog(pSKAT)$p}\n",
    "        else\n",
    "        {modskat <- pSKAT}\n",
    "\n",
    "        METAFIN <- c(as.character(ll[k,1]),as.character(ll[k,2]),as.character(ll[k,3]),sum(as.numeric(N)),sum(as.numeric(NVAR)),mod$TE.fixed,mod$seTE.fixed,mod$lower.fixed,mod$upper.fixed,mod$pval.fixed,modsyno$TE.fixed,modsyno$seTE.fixed,modsyno$lower.fixed,modsyno$upper.fixed,modsyno$pval.fixed,modskat,NA,modburden$TE.fixed,modburden$seTE.fixed,modburden$pval.fixed,max(as.numeric(SKATN)),paste0(length(pSKAT),\"/\",length(phenolistS)),NA)\n",
    "\n",
    "      }\n",
    "\n",
    "      if (length(beta) == 0 & length(pSKAT) > 0 & length(pSKATO) > 0)\n",
    "      {\n",
    "\n",
    "        modburden <- metagen(betaBURDEN,seBURDEN,studlab=seq(1:length(betaBURDEN)))\n",
    "\n",
    "        if (length(pSKAT) > 1)\n",
    "        {modskat <- sumlog(pSKAT)$p}\n",
    "        else\n",
    "        {modskat <- pSKAT}\n",
    "\n",
    "        if (length(pSKATO) > 1)\n",
    "        {modskatO <- sumlog(pSKATO)$p}\n",
    "        else\n",
    "        {modskatO <- pSKATO}\n",
    "\n",
    "        METAFIN <- c(as.character(ll[k,1]),as.character(ll[k,2]),as.character(ll[k,3]),NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,modskat,modskatO,modburden$TE.fixed,modburden$seTE.fixed,modburden$pval.fixed,max(as.numeric(SKATN)),paste0(length(pSKAT),\"/\",length(phenolistS)),paste0(length(pSKATO),\"/\",length(phenolistS)))\n",
    "\n",
    "      }\n",
    "\n",
    "      if (length(beta) == 0 & length(pSKAT) > 0 & length(pSKATO) == 0)\n",
    "      {\n",
    "\n",
    "        if (length(pSKAT) > 1)\n",
    "        {modskat <- sumlog(pSKAT)$p}\n",
    "        else\n",
    "        {modskat <- pSKAT}\n",
    "\n",
    "        METAFIN <- c(as.character(ll[k,1]),as.character(ll[k,2]),as.character(ll[k,3]),NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,modskat,NA,NA,NA,NA,max(as.numeric(SKATN)),paste0(length(pSKAT),\"/\",length(phenolistS)),NA)\n",
    "\n",
    "      }\n",
    "\n",
    "        METARES <- rbind(METARES,METAFIN)\n",
    "    }\n",
    "  }\n",
    "colnames(METARES) <- c(\"geneset_name\",\"freq_thsld\",\"dfilter\",\"N\",\"NVAR\",\"beta\",\"se\",\"lower_CI\",\"upper_CI\",\"pval\",\"beta_syno\",\"se_syno\",\"lower_CI_syno\",\"upper_CI_syno\",\"pval_syno\",\"SKAT_P\",\"SKATO_P\",\"BURDEN_BETA\",\"BURDEN_SE\",\"BURDEN_PVAL\",\"SKAT_NVAR\",\"N_studies_SKAT\",\"N_studies_SKATO\")\n",
    "return(METARES)\n",
    "}\n",
    "\n",
    "\n",
    "#### DEFINE GENE-SETS TO INCLUDE ####\n",
    "## We exclude only homozygous scores, scores including singletons and URV dubletons ###\n",
    "geneset <- unique(c(finC_finB$geneset_name,SfinC_finB$geneset_name))\n",
    "geneset <- geneset[!grepl(\"specific\",geneset)]\n",
    "freq_filter <- unique(c(finC_finB$freq_thsld,SfinC_finB$freq_thsld))\n",
    "freq_filter <- freq_filter[!grepl(\"SING|DOUBLEURV\",freq_filter)]\n",
    "dfilter <- unique(c(finC_finB$dfilter,SfinC_finB$dfilter))\n",
    "dfilter <- dfilter[!grepl(\"HOM$\",dfilter)]\n",
    "\n",
    "\n",
    "ll <- expand.grid(list(geneset,freq_filter,dfilter))\n",
    "\n",
    "\n",
    "### LDL ###\n",
    "print(\"LDL\")\n",
    "\n",
    "phenolist <- list(finC_finB[finC_finB$pheno == \"LDL\",],diabC_afrB[diabC_afrB$pheno==\"LDLQQ\",],diabC_amrB[diabC_amrB$pheno==\"LDLQQ\",],diabC_easB[diabC_easB$pheno==\"LDLQQ\",],diabC_nfeB[diabC_nfeB$pheno==\"LDLQQ\",],diabC_finB[diabC_finB$pheno==\"LDLQQ\",],diabC_sasB[diabC_sasB$pheno==\"LDLQQ\",],migenC_afrB[migenC_afrB$pheno==\"norm_LDL_BASELINE_ADJ\",],migenC_nfeB[migenC_nfeB$pheno==\"norm_LDL_BASELINE_ADJ\",],migenC_sasB[migenC_sasB$pheno==\"norm_LDL_BASELINE_ADJ\",],metC_finB[metC_finB$pheno==\"LDLQQ\",])\n",
    "phenolistS <- list(SfinC_finB[SfinC_finB$pheno == \"LDL\",],SdiabC_afrB[SdiabC_afrB$pheno==\"LDLQQ\",],SdiabC_amrB[SdiabC_amrB$pheno==\"LDLQQ\",],SdiabC_easB[SdiabC_easB$pheno==\"LDLQQ\",],SdiabC_nfeB[SdiabC_nfeB$pheno==\"LDLQQ\",],SdiabC_finB[SdiabC_finB$pheno==\"LDLQQ\",],SdiabC_sasB[SdiabC_sasB$pheno==\"LDLQQ\",],SmigenC_afrB[SmigenC_afrB$pheno==\"norm_LDL_BASELINE_ADJ\",],SmigenC_nfeB[SmigenC_nfeB$pheno==\"norm_LDL_BASELINE_ADJ\",],SmigenC_sasB[SmigenC_sasB$pheno==\"norm_LDL_BASELINE_ADJ\",],SmetC_finB[SmetC_finB$pheno==\"LDLQQ\",])\n",
    "\n",
    "METALDL <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### HDL ###\n",
    "print(\"HDL\")\n",
    "\n",
    "phenolist <- list(finC_finB[finC_finB$pheno == \"HDL\",],diabC_afrB[diabC_afrB$pheno==\"HDLQQ\",],diabC_amrB[diabC_amrB$pheno==\"HDLQQ\",],diabC_easB[diabC_easB$pheno==\"HDLQQ\",],diabC_nfeB[diabC_nfeB$pheno==\"HDLQQ\",],diabC_finB[diabC_finB$pheno==\"HDLQQ\",],diabC_sasB[diabC_sasB$pheno==\"HDLQQ\",],migenC_afrB[migenC_afrB$pheno==\"norm_HDL_BASELINE\",],migenC_nfeB[migenC_nfeB$pheno==\"norm_HDL_BASELINE\",],migenC_sasB[migenC_sasB$pheno==\"norm_HDL_BASELINE\",],metC_finB[metC_finB$pheno==\"HDLQQ\",])\n",
    "phenolistS <- list(SfinC_finB[SfinC_finB$pheno == \"HDL\",],SdiabC_afrB[SdiabC_afrB$pheno==\"HDLQQ\",],SdiabC_amrB[SdiabC_amrB$pheno==\"HDLQQ\",],SdiabC_easB[SdiabC_easB$pheno==\"HDLQQ\",],SdiabC_nfeB[SdiabC_nfeB$pheno==\"HDLQQ\",],SdiabC_finB[SdiabC_finB$pheno==\"HDLQQ\",],SdiabC_sasB[SdiabC_sasB$pheno==\"HDLQQ\",],SmigenC_afrB[SmigenC_afrB$pheno==\"norm_HDL_BASELINE\",],SmigenC_nfeB[SmigenC_nfeB$pheno==\"norm_HDL_BASELINE\",],SmigenC_sasB[SmigenC_sasB$pheno==\"norm_HDL_BASELINE\",],SmetC_finB[SmetC_finB$pheno==\"HDLQQ\",])\n",
    "\n",
    "METAHDL <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### TC ###\n",
    "print(\"TC\")\n",
    "\n",
    "phenolist <- list(finC_finB[finC_finB$pheno == \"TC\",],diabC_afrB[diabC_afrB$pheno==\"CHOLQQ\",],diabC_amrB[diabC_amrB$pheno==\"CHOLQQ\",],diabC_easB[diabC_easB$pheno==\"CHOLQQ\",],diabC_nfeB[diabC_nfeB$pheno==\"CHOLQQ\",],diabC_finB[diabC_finB$pheno==\"CHOLQQ\",],diabC_sasB[diabC_sasB$pheno==\"CHOLQQ\",],migenC_afrB[migenC_afrB$pheno==\"norm_TOTCHOL_BASELINE_ADJ\",],migenC_nfeB[migenC_nfeB$pheno==\"norm_TOTCHOL_BASELINE_ADJ\",],migenC_sasB[migenC_sasB$pheno==\"norm_TOTCHOL_BASELINE_ADJ\",],metC_finB[metC_finB$pheno==\"TCQQ\",])\n",
    "phenolistS <- list(SfinC_finB[SfinC_finB$pheno == \"TC\",],SdiabC_afrB[SdiabC_afrB$pheno==\"CHOLQQ\",],SdiabC_amrB[SdiabC_amrB$pheno==\"CHOLQQ\",],SdiabC_easB[SdiabC_easB$pheno==\"CHOLQQ\",],SdiabC_nfeB[SdiabC_nfeB$pheno==\"CHOLQQ\",],SdiabC_finB[SdiabC_finB$pheno==\"CHOLQQ\",],SdiabC_sasB[SdiabC_sasB$pheno==\"CHOLQQ\",],SmigenC_afrB[SmigenC_afrB$pheno==\"norm_TOTCHOL_BASELINE_ADJ\",],SmigenC_nfeB[SmigenC_nfeB$pheno==\"norm_TOTCHOL_BASELINE_ADJ\",],SmigenC_sasB[SmigenC_sasB$pheno==\"norm_TOTCHOL_BASELINE_ADJ\",],SmetC_finB[SmetC_finB$pheno==\"TCQQ\",])\n",
    "\n",
    "METATC <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### TG ###\n",
    "print(\"TG\")\n",
    "\n",
    "phenolist <- list(finC2_finB[finC2_finB$pheno == \"TG\",],diabC_afrB[diabC_afrB$pheno==\"TGQQ\",],diabC_amrB[diabC_amrB$pheno==\"TGQQ\",],diabC_easB[diabC_easB$pheno==\"TGQQ\",],diabC_nfeB[diabC_nfeB$pheno==\"TGQQ\",],diabC_finB[diabC_finB$pheno==\"TGQQ\",],diabC_sasB[diabC_sasB$pheno==\"TGQQ\",],migenC_afrB[migenC_afrB$pheno==\"norm_LOG_TRIG_BASELINE\",],migenC_nfeB[migenC_nfeB$pheno==\"norm_LOG_TRIG_BASELINE\",],migenC_sasB[migenC_sasB$pheno==\"norm_LOG_TRIG_BASELINE\",],metC_finB[metC_finB$pheno==\"TGQQ\",])\n",
    "phenolistS <- list(SfinC2_finB[SfinC2_finB$pheno == \"TG\",],SdiabC_afrB[SdiabC_afrB$pheno==\"TGQQ\",],SdiabC_amrB[SdiabC_amrB$pheno==\"TGQQ\",],SdiabC_easB[SdiabC_easB$pheno==\"TGQQ\",],SdiabC_nfeB[SdiabC_nfeB$pheno==\"TGQQ\",],SdiabC_finB[SdiabC_finB$pheno==\"TGQQ\",],SdiabC_sasB[SdiabC_sasB$pheno==\"TGQQ\",],SmigenC_afrB[SmigenC_afrB$pheno==\"norm_LOG_TRIG_BASELINE\",],SmigenC_nfeB[SmigenC_nfeB$pheno==\"norm_LOG_TRIG_BASELINE\",],SmigenC_sasB[SmigenC_sasB$pheno==\"norm_LOG_TRIG_BASELINE\",],SmetC_finB[SmetC_finB$pheno==\"TGQQ\",])\n",
    "\n",
    "METATG <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### SBP ###\n",
    "print(\"SBP\")\n",
    "\n",
    "phenolist <- list(finC_finB[finC_finB$pheno == \"SBP\",],sweC2_nfeB[sweC2_nfeB$pheno==\"SYST\",],diabC_afrB[diabC_afrB$pheno==\"SBPQQ\",],diabC_amrB[diabC_amrB$pheno==\"SBPQQ\",],diabC_easB[diabC_easB$pheno==\"SBPQQ\",],diabC_nfeB[diabC_nfeB$pheno==\"SBPQQ\",],diabC_finB[diabC_finB$pheno==\"SBPQQ\",],diabC_sasB[diabC_sasB$pheno==\"SBPQQ\",],migenC_afrB[migenC_afrB$pheno==\"norm_SBP_BASELINE\",],migenC_nfeB[migenC_nfeB$pheno==\"norm_SBP_BASELINE\",],migenC_sasB[migenC_sasB$pheno==\"norm_SBP_BASELINE\",],metC_finB[metC_finB$pheno==\"SBPQQ\",])\n",
    "phenolistS <- list(SfinC_finB[SfinC_finB$pheno == \"SBP\",],SsweC2_nfeB[SsweC2_nfeB$pheno==\"SYST\",],SdiabC_afrB[SdiabC_afrB$pheno==\"SBPQQ\",],SdiabC_amrB[SdiabC_amrB$pheno==\"SBPQQ\",],SdiabC_easB[SdiabC_easB$pheno==\"SBPQQ\",],SdiabC_nfeB[SdiabC_nfeB$pheno==\"SBPQQ\",],SdiabC_finB[SdiabC_finB$pheno==\"SBPQQ\",],SdiabC_sasB[SdiabC_sasB$pheno==\"SBPQQ\",],SmigenC_afrB[SmigenC_afrB$pheno==\"norm_SBP_BASELINE\",],SmigenC_nfeB[SmigenC_nfeB$pheno==\"norm_SBP_BASELINE\",],SmigenC_sasB[SmigenC_sasB$pheno==\"norm_SBP_BASELINE\",],SmetC_finB[SmetC_finB$pheno==\"SBPQQ\",])\n",
    "\n",
    "METASBP <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### DBP ###\n",
    "print(\"DBP\")\n",
    "\n",
    "phenolist <- list(finC_finB[finC_finB$pheno == \"DBP\",],sweC2_nfeB[sweC2_nfeB$pheno==\"DIAS\",],diabC_afrB[diabC_afrB$pheno==\"DBPQQ\",],diabC_amrB[diabC_amrB$pheno==\"DBPQQ\",],diabC_easB[diabC_easB$pheno==\"DBPQQ\",],diabC_nfeB[diabC_nfeB$pheno==\"DBPQQ\",],diabC_finB[diabC_finB$pheno==\"DBPQQ\",],diabC_sasB[diabC_sasB$pheno==\"DBPQQ\",],migenC_afrB[migenC_afrB$pheno==\"norm_DBP_BASELINE\",],migenC_nfeB[migenC_nfeB$pheno==\"norm_DBP_BASELINE\",],migenC_sasB[migenC_sasB$pheno==\"norm_DBP_BASELINE\",],metC_finB[metC_finB$pheno==\"DBP\",])\n",
    "phenolistS <- list(SfinC_finB[SfinC_finB$pheno == \"DBP\",],SsweC2_nfeB[SsweC2_nfeB$pheno==\"DIAS\",],SdiabC_afrB[SdiabC_afrB$pheno==\"DBPQQ\",],SdiabC_amrB[SdiabC_amrB$pheno==\"DBPQQ\",],SdiabC_easB[SdiabC_easB$pheno==\"DBPQQ\",],SdiabC_nfeB[SdiabC_nfeB$pheno==\"DBPQQ\",],SdiabC_finB[SdiabC_finB$pheno==\"DBPQQ\",],SdiabC_sasB[SdiabC_sasB$pheno==\"DBPQQ\",],SmigenC_afrB[SmigenC_afrB$pheno==\"norm_DBP_BASELINE\",],SmigenC_nfeB[SmigenC_nfeB$pheno==\"norm_DBP_BASELINE\",],SmigenC_sasB[SmigenC_sasB$pheno==\"norm_DBP_BASELINE\",],SmetC_finB[SmetC_finB$pheno==\"DBP\",])\n",
    "\n",
    "METADBP <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "## HEIGHT ##\n",
    "print(\"HEIGHT\")\n",
    "\n",
    "phenolist <- list(finC_finB[finC_finB$pheno == \"HEIGHT\",],sweC2_nfeB[sweC2_nfeB$pheno==\"LNGD\",],migenC_afrB[migenC_afrB$pheno==\"norm_HEIGHT_BASELINE\",],migenC_nfeB[migenC_nfeB$pheno==\"norm_HEIGHT_BASELINE\",],migenC_sasB[migenC_sasB$pheno==\"norm_HEIGHT_BASELINE\",],metC_finB[metC_finB$pheno==\"HEIGHTQQ\",])\n",
    "phenolistS <- list(SfinC_finB[SfinC_finB$pheno == \"HEIGHT\",],SsweC2_nfeB[SsweC2_nfeB$pheno==\"LNGD\",],SmigenC_afrB[SmigenC_afrB$pheno==\"norm_HEIGHT_BASELINE\",],SmigenC_nfeB[SmigenC_nfeB$pheno==\"norm_HEIGHT_BASELINE\",],SmigenC_sasB[SmigenC_sasB$pheno==\"norm_HEIGHT_BASELINE\",],SmetC_finB[SmetC_finB$pheno==\"HEIGHTQQ\",])\n",
    "\n",
    "METALNGD <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "\n",
    "### HEIGHT-RAW ###\n",
    "print(\"HEIGHT-raw\")\n",
    "\n",
    "phenolist <- list(finC_finB[finC_finB$pheno == \"HEIGHT_RAW\",],sweC2_nfeB[sweC2_nfeB$pheno==\"LNGD_RAW\",],migenC_afrB[migenC_afrB$pheno==\"HEIGHT_BASELINE\",],migenC_nfeB[migenC_nfeB$pheno==\"HEIGHT_BASELINE\",],migenC_sasB[migenC_sasB$pheno==\"HEIGHT_BASELINE\",],metC_finB[metC_finB$pheno==\"HEIGHT\",])\n",
    "phenolistS <- list(SfinC_finB[SfinC_finB$pheno == \"HEIGHT_RAW\",],SsweC2_nfeB[SsweC2_nfeB$pheno==\"LNGD_RAW\",],SmigenC_afrB[SmigenC_afrB$pheno==\"HEIGHT_BASELINE\",],SmigenC_nfeB[SmigenC_nfeB$pheno==\"HEIGHT_BASELINE\",],SmigenC_sasB[SmigenC_sasB$pheno==\"HEIGHT_BASELINE\",],SmetC_finB[SmetC_finB$pheno==\"HEIGHT\",])\n",
    "\n",
    "METALNGDRAW <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### BMI ###\n",
    "print(\"BMI\")\n",
    "\n",
    "phenolist <- list(finC_finB[finC_finB$pheno == \"BMI\",],sweC2_nfeB[sweC2_nfeB$pheno==\"BMI\",],diabC_afrB[diabC_afrB$pheno==\"BMIQQ\",],diabC_amrB[diabC_amrB$pheno==\"BMIQQ\",],diabC_easB[diabC_easB$pheno==\"BMIQQ\",],diabC_nfeB[diabC_nfeB$pheno==\"BMIQQ\",],diabC_finB[diabC_finB$pheno==\"BMIQQ\",],diabC_sasB[diabC_sasB$pheno==\"BMIQQ\",],migenC_afrB[migenC_afrB$pheno==\"norm_BMI_BASELINE\",],migenC_nfeB[migenC_nfeB$pheno==\"norm_BMI_BASELINE\",],migenC_sasB[migenC_sasB$pheno==\"norm_BMI_BASELINE\",],metC_finB[metC_finB$pheno==\"BMIQQ\",])\n",
    "phenolistS <- list(SfinC_finB[SfinC_finB$pheno == \"BMI\",],SsweC2_nfeB[SsweC2_nfeB$pheno==\"BMI\",],SdiabC_afrB[SdiabC_afrB$pheno==\"BMIQQ\",],SdiabC_amrB[SdiabC_amrB$pheno==\"BMIQQ\",],SdiabC_easB[SdiabC_easB$pheno==\"BMIQQ\",],SdiabC_nfeB[SdiabC_nfeB$pheno==\"BMIQQ\",],SdiabC_finB[SdiabC_finB$pheno==\"BMIQQ\",],SdiabC_sasB[SdiabC_sasB$pheno==\"BMIQQ\",],SmigenC_afrB[SmigenC_afrB$pheno==\"norm_BMI_BASELINE\",],SmigenC_nfeB[SmigenC_nfeB$pheno==\"norm_BMI_BASELINE\",],SmigenC_sasB[SmigenC_sasB$pheno==\"norm_BMI_BASELINE\",],SmetC_finB[SmetC_finB$pheno==\"BMIQQ\",])\n",
    "\n",
    "METABMI <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### GLUCOSEADJBMI ###\n",
    "print(\"GLUCOSEADJBMI\")\n",
    "\n",
    "phenolist <- list(finC3_finB[finC3_finB$pheno == \"GLUCOSE\",],diabC2_afrB[diabC2_afrB$pheno==\"FAST_GLUQQ\",],diabC2_amrB[diabC2_amrB$pheno==\"FAST_GLUQQ\",],diabC2_easB[diabC2_easB$pheno==\"FAST_GLUQQ\",],diabC2_nfeB[diabC2_nfeB$pheno==\"FAST_GLUQQ\",],diabC2_finB[diabC2_finB$pheno==\"FAST_GLUQQ\",],diabC2_sasB[diabC2_sasB$pheno==\"FAST_GLUQQ\",],metC3_finB[metC3_finB$pheno==\"GLUCOSEQQ\",])\n",
    "phenolistS <- list(SfinC3_finB[SfinC3_finB$pheno == \"GLUCOSE\",],SdiabC2_afrB[SdiabC2_afrB$pheno==\"FAST_GLUQQ\",],SdiabC2_amrB[SdiabC2_amrB$pheno==\"FAST_GLUQQ\",],SdiabC2_easB[SdiabC2_easB$pheno==\"FAST_GLUQQ\",],SdiabC2_nfeB[SdiabC2_nfeB$pheno==\"FAST_GLUQQ\",],SdiabC2_finB[SdiabC2_finB$pheno==\"FAST_GLUQQ\",],SdiabC2_sasB[SdiabC2_sasB$pheno==\"FAST_GLUQQ\",],SmetC3_finB[SmetC3_finB$pheno==\"GLUCOSEQQ\",])\n",
    "\n",
    "METAADJGLUCOSE <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### INSULINEADJBMI ###\n",
    "print(\"INSADJBMI\")\n",
    "\n",
    "phenolist <- list(finC3_finB[finC3_finB$pheno == \"INS\",],diabC2_afrB[diabC2_afrB$pheno==\"FAST_INSQQ\",],diabC2_amrB[diabC2_amrB$pheno==\"FAST_INSQQ\",],diabC2_easB[diabC2_easB$pheno==\"FAST_INSQQ\",],diabC2_nfeB[diabC2_nfeB$pheno==\"FAST_INSQQ\",],diabC2_finB[diabC2_finB$pheno==\"FAST_INSQQ\",],diabC2_sasB[diabC2_sasB$pheno==\"FAST_INSQQ\",],metC3_finB[metC3_finB$pheno==\"INSQQ\",])\n",
    "phenolistS <- list(SfinC3_finB[SfinC3_finB$pheno == \"INS\",],SdiabC2_afrB[SdiabC2_afrB$pheno==\"FAST_INSQQ\",],SdiabC2_amrB[SdiabC2_amrB$pheno==\"FAST_INSQQ\",],SdiabC2_easB[SdiabC2_easB$pheno==\"FAST_INSQQ\",],SdiabC2_nfeB[SdiabC2_nfeB$pheno==\"FAST_INSQQ\",],SdiabC2_finB[SdiabC2_finB$pheno==\"FAST_INSQQ\",],SdiabC2_sasB[SdiabC2_sasB$pheno==\"FAST_INSQQ\",],SmetC3_finB[SmetC3_finB$pheno==\"INSQQ\",])\n",
    "\n",
    "METAADJINS <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### EDUCATION ###\n",
    "print(\"EDU\")\n",
    "\n",
    "phenolist <- list(finC_finB[finC_finB$pheno == \"yearsofedu\",],sweC_nfeB[sweC_nfeB$pheno==\"yearsofedu\",])\n",
    "phenolistS <- list(SfinC_finB[SfinC_finB$pheno == \"yearsofedu\",],SsweC_nfeB[SsweC_nfeB$pheno==\"yearsofedu\",])\n",
    "\n",
    "METAEDU <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### EDUCATION - RAW ###\n",
    "print(\"EDU-raw\")\n",
    "\n",
    "phenolist <- list(finC_finB[finC_finB$pheno == \"yearsofedu_raw\",],sweC_nfeB[sweC_nfeB$pheno==\"yearsofedu_raw\",])\n",
    "phenolistS <- list(SfinC_finB[SfinC_finB$pheno == \"yearsofedu_raw\",],SsweC_nfeB[SsweC_nfeB$pheno==\"yearsofedu_raw\",])\n",
    "\n",
    "METAEDURAW <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### AGE ###\n",
    "print(\"AGE\")\n",
    "\n",
    "phenolist <- list(finC4_finB[finC4_finB$pheno == \"ageqq\",],diabC3_afrB[diabC3_afrB$pheno==\"ageqq\",],diabC3_easB[diabC3_easB$pheno==\"ageqq\",],diabC3_nfeB[diabC3_nfeB$pheno==\"ageqq\",],diabC3_finB[diabC3_finB$pheno==\"ageqq\",],diabC3_sasB[diabC3_sasB$pheno==\"ageqq\",],sweC3_nfeB[sweC3_nfeB$pheno==\"ageqq\",],diabC3_amrB[diabC3_amrB$pheno==\"ageqq\",],migenC2_afrB[migenC2_afrB$pheno==\"ageqq\",],migenC2_nfeB[migenC2_nfeB$pheno==\"ageqq\",],migenC2_sasB[migenC2_sasB$pheno==\"ageqq\",],metC2_finB[metC2_finB$pheno==\"AGEQQ\",])\n",
    "phenolistS <- list(SfinC4_finB[SfinC4_finB$pheno == \"ageqq\",],SdiabC3_afrB[SdiabC3_afrB$pheno==\"ageqq\",],SdiabC3_easB[SdiabC3_easB$pheno==\"ageqq\",],SdiabC3_nfeB[SdiabC3_nfeB$pheno==\"ageqq\",],SdiabC3_finB[SdiabC3_finB$pheno==\"ageqq\",],SdiabC3_sasB[SdiabC3_sasB$pheno==\"ageqq\",],SsweC3_nfeB[SsweC3_nfeB$pheno==\"ageqq\",],SdiabC3_amrB[SdiabC3_amrB$pheno==\"ageqq\",],SmigenC2_afrB[SmigenC2_afrB$pheno==\"ageqq\",],SmigenC2_nfeB[SmigenC2_nfeB$pheno==\"ageqq\",],SmigenC2_sasB[SmigenC2_sasB$pheno==\"ageqq\",],SmetC2_finB[SmetC2_finB$pheno==\"AGEQQ\",])\n",
    "\n",
    "METAAGE <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### AGE - RAW ###\n",
    "phenolist <- list(finC4_finB[finC4_finB$pheno == \"AGE\",],diabC3_afrB[diabC3_afrB$pheno==\"AGE\",],diabC3_easB[diabC3_easB$pheno==\"AGE\",],diabC3_nfeB[diabC3_nfeB$pheno==\"AGE\",],diabC3_finB[diabC3_finB$pheno==\"AGE\",],diabC3_sasB[diabC3_sasB$pheno==\"AGE\",],sweC3_nfeB[sweC3_nfeB$pheno==\"age\",],diabC3_amrB[diabC3_amrB$pheno==\"AGE\",],migenC2_afrB[migenC2_afrB$pheno==\"AGE\",],migenC2_nfeB[migenC2_nfeB$pheno==\"AGE\",],migenC2_sasB[migenC2_sasB$pheno==\"AGE\",],metC2_finB[metC2_finB$pheno==\"AGE\",])\n",
    "phenolistS <- list(SfinC4_finB[SfinC4_finB$pheno == \"AGE\",],SdiabC3_afrB[SdiabC3_afrB$pheno==\"AGE\",],SdiabC3_easB[SdiabC3_easB$pheno==\"AGE\",],SdiabC3_nfeB[SdiabC3_nfeB$pheno==\"AGE\",],SdiabC3_finB[SdiabC3_finB$pheno==\"AGE\",],SdiabC3_sasB[SdiabC3_sasB$pheno==\"AGE\",],SsweC3_nfeB[SsweC3_nfeB$pheno==\"age\",],SdiabC3_amrB[SdiabC3_amrB$pheno==\"AGE\",],SmigenC2_afrB[SmigenC2_afrB$pheno==\"AGE\",],SmigenC2_nfeB[SmigenC2_nfeB$pheno==\"AGE\",],SmigenC2_sasB[SmigenC2_sasB$pheno==\"AGE\",],SmetC2_finB[SmetC2_finB$pheno==\"AGE\",])\n",
    "\n",
    "METAAGERAW <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### BIRTH WEIGHT ADJ BMI ###\n",
    "print(\"BWADJGAGE\")\n",
    "\n",
    "phenolist <- list(dbsC_nfeB[dbsC_nfeB$pheno==\"BWGHT_ADJGE\",])\n",
    "phenolistS <- list(SdbsC_nfeB[SdbsC_nfeB$pheno==\"BWGHT_ADJGE\",])\n",
    "\n",
    "METABWADJBMI <- METAC(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### SCZ AGE ###\n",
    "phenolist <- list(dbsCSCZ_nfeB[dbsCSCZ_nfeB$pheno==\"AGESCZ\",])\n",
    "phenolistS <- list(SdbsCSCZ_nfeB[SdbsCSCZ_nfeB$pheno==\"AGESCZ\",])\n",
    "\n",
    "METASCZAGE <- METAC(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "### BP AGE ###\n",
    "phenolist <- list(dbsCBP_nfeB[dbsCBP_nfeB$pheno==\"AGEBP\",])\n",
    "phenolistS <- list(SdbsCBP_nfeB[SdbsCBP_nfeB$pheno==\"AGEBP\",])\n",
    "\n",
    "METABPAGE <- METAC(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "### AUTISM AGE ###\n",
    "phenolist <- list(dbsCAUTISM_nfeB[dbsCAUTISM_nfeB$pheno==\"AGEAUTISM\",])\n",
    "phenolistS <- list(SdbsCAUTISM_nfeB[SdbsCAUTISM_nfeB$pheno==\"AGEAUTISM\",])\n",
    "\n",
    "METAAUTISMAGE <- METAC(phenolist,NULL,ll)\n",
    "\n",
    "### ADHD AGE ###\n",
    "phenolist <- list(dbsCADHD_nfeB[dbsCADHD_nfeB$pheno==\"AGEADHDD\",])\n",
    "phenolistS <- list(SdbsCADHD_nfeB[SdbsCADHD_nfeB$pheno==\"AGEADHDD\",])\n",
    "\n",
    "METAADHDAGE <- METAC(phenolist,NULL,ll)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for dichotomous outcomes: t2d, ibd, uc, cd, early onset mi, chd, id, scz, bp, autism, adhd. Dor scz, bp, autism, adhd we considered male and female separately, as well as having subsets considering no overlap with with other relevant co-morbidities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "METAD <- function(phenolist,phenolistS=NULL,ll)\n",
    "{\n",
    "  METARES <- NULL\n",
    "  if (is.null(phenolistS))\n",
    "  {\n",
    "    for (k in 1:nrow(ll))\n",
    "    {\n",
    "      \n",
    "      beta <- unlist(sapply(phenolist,function(x){x$beta_x[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      se <- unlist(sapply(phenolist,function(x){x$se_x[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      N_CASES <- unlist(sapply(phenolist,function(x){x$N_CASES[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      N_CNTL <- unlist(sapply(phenolist,function(x){x$N_CNTL[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      TOTVAR_CNTL <- unlist(sapply(phenolist,function(x){x$TOTVAR_CNTL[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      TOTVAR_CASES <- unlist(sapply(phenolist,function(x){x$TOTVAR_CASES[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      beta_syno <- unlist(sapply(phenolist,function(x){x$beta_syno[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      se_syno <- unlist(sapply(phenolist,function(x){x$se_syno[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      if (length(beta) > 0)\n",
    "      {\n",
    "        mod <- metagen(beta,se,studlab=seq(1:length(beta)))\n",
    "        modsyno <- metagen(beta_syno,se_syno,studlab=seq(1:length(beta_syno)))\n",
    "        METAFIN <- c(as.character(ll[k,1]),as.character(ll[k,2]),as.character(ll[k,3]),sum(N_CASES),sum(N_CNTL),sum(TOTVAR_CASES),sum(TOTVAR_CNTL),mod$TE.fixed,mod$seTE.fixed,mod$lower.fixed,mod$upper.fixed,mod$pval.fixed,modsyno$TE.fixed,modsyno$seTE.fixed,modsyno$lower.fixed,modsyno$upper.fixed,modsyno$pval.fixed,NA,NA,NA,NA,NA,NA,NA,NA)\n",
    "\n",
    "        METARES <- rbind(METARES,METAFIN)\n",
    "\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  else\n",
    "  {\n",
    "    for (k in 1:nrow(ll))\n",
    "    {\n",
    "\n",
    "      METAFIN <- NULL\n",
    "\n",
    "      beta <- unlist(sapply(phenolist,function(x){x$beta_x[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      se <- unlist(sapply(phenolist,function(x){x$se_x[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      N_CASES <- unlist(sapply(phenolist,function(x){x$N_CASES[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      N_CNTL <- unlist(sapply(phenolist,function(x){x$N_CNTL[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      TOTVAR_CNTL <- unlist(sapply(phenolist,function(x){x$TOTVAR_CNTL[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      TOTVAR_CASES <- unlist(sapply(phenolist,function(x){x$TOTVAR_CASES[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      beta_syno <- unlist(sapply(phenolist,function(x){x$beta_syno[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      se_syno <- unlist(sapply(phenolist,function(x){x$se_syno[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      pSKAT <- unlist(sapply(phenolistS,function(x){x$p_x[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      pSKATO <- unlist(sapply(phenolistS,function(x){x$SKATO_PVAL[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      betaBURDEN <- unlist(sapply(phenolistS,function(x){x$co_burden[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "      seBURDEN <- unlist(sapply(phenolistS,function(x){x$se_burden[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "\n",
    "      SKATN <- unlist(sapply(phenolistS,function(x){x$nmarker[x$geneset_name==ll[k,1] & x$freq_thsld==ll[k,2] & x$dfilter==ll[k,3]]}))\n",
    "\n",
    "      pSKAT[pSKAT==0] <- 1e-16\n",
    "      pSKATO[pSKATO==0] <- 1e-16\n",
    "      pSKAT[pSKAT>1] <- NA\n",
    "      pSKATO[pSKATO>1] <- NA\n",
    "\n",
    "      pSKAT <- pSKAT[!is.na(pSKAT)]\n",
    "      if(length(pSKATO)>1)\n",
    "      {pSKATO <- pSKATO[!is.na(pSKATO)]}\n",
    "\n",
    "      if (length(beta) > 0 & length(pSKAT) == 0 & length(pSKATO) == 0)\n",
    "      {\n",
    "        mod <- metagen(beta,se,studlab=seq(1:length(beta)))\n",
    "        modsyno <- metagen(beta_syno,se_syno,studlab=seq(1:length(beta_syno)))\n",
    "\n",
    "        METAFIN <- c(as.character(ll[k,1]),as.character(ll[k,2]),as.character(ll[k,3]),sum(N_CASES),sum(N_CNTL),sum(TOTVAR_CASES),sum(TOTVAR_CNTL),mod$TE.fixed,mod$seTE.fixed,mod$lower.fixed,mod$upper.fixed,mod$pval.fixed,modsyno$TE.fixed,modsyno$seTE.fixed,modsyno$lower.fixed,modsyno$upper.fixed,modsyno$pval.fixed,NA,NA,NA,NA,NA,NA,NA,NA)\n",
    "\n",
    "      }\n",
    "     \n",
    "      if (length(beta) > 0 & length(pSKAT) > 0 & length(pSKATO) > 0)\n",
    "      {\n",
    "        mod <- metagen(beta,se,studlab=seq(1:length(beta)))\n",
    "        modsyno <- metagen(beta_syno,se_syno,studlab=seq(1:length(beta_syno)))\n",
    "\n",
    "        modburden <- metagen(betaBURDEN,seBURDEN,studlab=seq(1:length(betaBURDEN)))\n",
    "\n",
    "        if (length(pSKAT) > 1)\n",
    "        {modskat <- sumlog(pSKAT)$p}\n",
    "        else\n",
    "        {modskat <- pSKAT}\n",
    "\n",
    "        if (length(pSKATO) > 1)\n",
    "        {modskatO <- sumlog(pSKATO)$p}\n",
    "        else\n",
    "        {modskatO <- pSKATO}\n",
    "        \n",
    "\n",
    "        METAFIN <- c(as.character(ll[k,1]),as.character(ll[k,2]),as.character(ll[k,3]),sum(N_CASES),sum(N_CNTL),sum(TOTVAR_CASES),sum(TOTVAR_CNTL),mod$TE.fixed,mod$seTE.fixed,mod$lower.fixed,mod$upper.fixed,mod$pval.fixed,modsyno$TE.fixed,modsyno$seTE.fixed,modsyno$lower.fixed,modsyno$upper.fixed,modsyno$pval.fixed,modskat,modskatO,modburden$TE.fixed,modburden$seTE.fixed,modburden$pval.fixed,max(as.numeric(SKATN)),paste0(length(pSKAT),\"/\",length(phenolistS)),paste0(length(pSKATO),\"/\",length(phenolistS)))\n",
    "      }\n",
    "\n",
    "      if (length(beta) > 0 & length(pSKAT) > 0 & length(pSKATO) == 0)\n",
    "      {\n",
    "        mod <- metagen(beta,se,studlab=seq(1:length(beta)))\n",
    "        modsyno <- metagen(beta_syno,se_syno,studlab=seq(1:length(beta_syno)))\n",
    "\n",
    "        modburden <- metagen(betaBURDEN,seBURDEN,studlab=seq(1:length(betaBURDEN)))\n",
    "\n",
    "\n",
    "        if (length(pSKAT) > 1)\n",
    "        {modskat <- sumlog(pSKAT)$p}\n",
    "        else\n",
    "        {modskat <- pSKAT}\n",
    "\n",
    "        METAFIN <- c(as.character(ll[k,1]),as.character(ll[k,2]),as.character(ll[k,3]),sum(N_CASES),sum(N_CNTL),sum(TOTVAR_CASES),sum(TOTVAR_CNTL),mod$TE.fixed,mod$seTE.fixed,mod$lower.fixed,mod$upper.fixed,mod$pval.fixed,modsyno$TE.fixed,modsyno$seTE.fixed,modsyno$lower.fixed,modsyno$upper.fixed,modsyno$pval.fixed,modskat,NA,modburden$TE.fixed,modburden$seTE.fixed,modburden$pval.fixed,max(as.numeric(SKATN)),paste0(length(pSKAT),\"/\",length(phenolistS)),NA)\n",
    "\n",
    "      }\n",
    "\n",
    "      if (length(beta) == 0 & length(pSKAT) > 0 & length(pSKATO) > 0)\n",
    "      {\n",
    "\n",
    "        modburden <- metagen(betaBURDEN,seBURDEN,studlab=seq(1:length(betaBURDEN)))\n",
    "\n",
    "        if (length(pSKAT) > 1)\n",
    "        {modskat <- sumlog(pSKAT)$p}\n",
    "        else\n",
    "        {modskat <- pSKAT}\n",
    "\n",
    "        if (length(pSKATO) > 1)\n",
    "        {modskatO <- sumlog(pSKATO)$p}\n",
    "        else\n",
    "        {modskatO <- pSKATO}\n",
    "\n",
    "        METAFIN <- c(as.character(ll[k,1]),as.character(ll[k,2]),as.character(ll[k,3]),NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,modskat,modskatO,modburden$TE.fixed,modburden$seTE.fixed,modburden$pval.fixed,max(as.numeric(SKATN)),paste0(length(pSKAT),\"/\",length(phenolistS)),paste0(length(pSKATO),\"/\",length(phenolistS)))\n",
    "      }\n",
    "\n",
    "      if (length(beta) == 0 & length(pSKAT) > 0 & length(pSKATO) == 0)\n",
    "\n",
    "      {\n",
    "\n",
    "        if (length(pSKAT) > 1)\n",
    "        {modskat <- sumlog(pSKAT)$p}\n",
    "        else\n",
    "        {modskat <- pSKAT}\n",
    "\n",
    "        METAFIN <- c(as.character(ll[k,1]),as.character(ll[k,2]),as.character(ll[k,3]),NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,modskat,NA,NA,NA,NA,max(as.numeric(SKATN)),paste0(length(pSKAT),\"/\",length(phenolistS)),NA)\n",
    "\n",
    "      }\n",
    "\n",
    "        METARES <- rbind(METARES,METAFIN)\n",
    "    }\n",
    "  }\n",
    "colnames(METARES) <- c(\"geneset_name\",\"freq_thsld\",\"dfilter\",\"N_CASES\",\"N_CNTL\",\"TOTVAR_CASES\",\"TOTVAR_CNTL\",\"beta\",\"se\",\"lower_CI\",\"upper_CI\",\"pval\",\"beta_syno\",\"se_syno\",\"lower_CI_syno\",\"upper_CI_syno\",\"pval_syno\",\"SKAT_P\",\"SKATO_P\",\"BURDEN_BETA\",\"BURDEN_SE\",\"BURDEN_PVAL\",\"SKAT_NVAR\",\"N_studies_SKAT\",\"N_studies_SKATO\")\n",
    "return(METARES)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "### T2D ###\n",
    "print(\"T2D\")\n",
    "\n",
    "phenolist <- list(diabD_afrB[diabD_afrB$pheno==\"T2D\",],diabD_amrB[diabD_amrB$pheno==\"T2D\",],diabD_easB[diabD_easB$pheno==\"T2D\",],diabD_nfeB[diabD_nfeB$pheno==\"T2D\",],diabD_finB[diabD_finB$pheno==\"T2D\",],diabD_sasB[diabD_sasB$pheno==\"T2D\",],migenD_afrB[migenD_afrB$pheno==\"T2D_BASELINE\",],migenD_nfeB[migenD_nfeB$pheno==\"T2D_BASELINE\",],migenD_sasB[migenD_sasB$pheno==\"T2D_BASELINE\",])\n",
    "phenolistS <- list(SdiabD_afrB[SdiabD_afrB$pheno==\"T2D\",],SdiabD_amrB[SdiabD_amrB$pheno==\"T2D\",],SdiabD_easB[SdiabD_easB$pheno==\"T2D\",],SdiabD_nfeB[SdiabD_nfeB$pheno==\"T2D\",],SdiabD_finB[SdiabD_finB$pheno==\"T2D\",],SdiabD_sasB[SdiabD_sasB$pheno==\"T2D\",],SmigenD_afrB[SmigenD_afrB$pheno==\"T2D_BASELINE\",],SmigenD_nfeB[SmigenD_nfeB$pheno==\"T2D_BASELINE\",],SmigenD_sasB[SmigenD_sasB$pheno==\"T2D_BASELINE\",])\n",
    "\n",
    "METAT2D <- METAD(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### IBD ###\n",
    "print(\"IBD\")\n",
    "\n",
    "phenolist <- list(ibdD_nfeB[ibdD_nfeB$pheno==\"IBD\",],ibdD_finB[ibdD_finB$pheno==\"IBD\",],ibdD_askB[ibdD_askB$pheno==\"IBD\",])\n",
    "phenolistS <- list(SibdD_nfeB[SibdD_nfeB$pheno==\"IBD\",],SibdD_finB[SibdD_finB$pheno==\"IBD\",],SibdD_askB[SibdD_askB$pheno==\"IBD\",])\n",
    "\n",
    "METAIBD <- METAD(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### UC ###\n",
    "print(\"UC\")\n",
    "\n",
    "phenolist <- list(ibdD_nfeB[ibdD_nfeB$pheno==\"UC\",],ibdD_finB[ibdD_finB$pheno==\"UC\",],ibdD_askB[ibdD_askB$pheno==\"UC\",])\n",
    "phenolistS <- list(SibdD_nfeB[SibdD_nfeB$pheno==\"UC\",],SibdD_finB[SibdD_finB$pheno==\"UC\",],SibdD_askB[SibdD_askB$pheno==\"UC\",])\n",
    "\n",
    "METAUC <- METAD(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "\n",
    "### CD ###\n",
    "print(\"CD\")\n",
    "\n",
    "phenolist <- list(ibdD_finB[ibdD_finB$pheno==\"CD\",],ibdD_nfeB[ibdD_nfeB$pheno==\"CD\",],ibdD_askB[ibdD_askB$pheno==\"CD\",])\n",
    "phenolistS <- list(SibdD_finB[SibdD_finB$pheno==\"CD\",],SibdD_nfeB[SibdD_nfeB$pheno==\"CD\",],SibdD_askB[SibdD_askB$pheno==\"CD\",])\n",
    "\n",
    "METACD <- METAD(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "\n",
    "### Early ONSET MI ##\n",
    "print(\"EOMI\")\n",
    "\n",
    "phenolist <- list(migenD2_afrB[migenD2_afrB$pheno==\"EOMI\",],migenD2_nfeB[migenD2_nfeB$pheno==\"EOMI\",],migenD2_sasB[migenD2_sasB$pheno==\"EOMI\",])\n",
    "phenolistS <- list(SmigenD2_afrB[SmigenD2_afrB$pheno==\"EOMI\",],SmigenD2_nfeB[SmigenD2_nfeB$pheno==\"EOMI\",],SmigenD2_sasB[SmigenD2_sasB$pheno==\"EOMI\",])\n",
    "\n",
    "METAEOMI <- METAD(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### CHD ###\n",
    "print(\"CHD\")\n",
    "\n",
    "phenolist <- list(migenD2_afrB[migenD2_afrB$pheno==\"CHD\",],migenD2_nfeB[migenD2_nfeB$pheno==\"CHD\",],migenD2_sasB[migenD2_sasB$pheno==\"CHD\",])\n",
    "phenolistS <- list(SmigenD2_afrB[SmigenD2_afrB$pheno==\"CHD\",],SmigenD2_nfeB[SmigenD2_nfeB$pheno==\"CHD\",],SmigenD2_sasB[SmigenD2_sasB$pheno==\"CHD\",])\n",
    "\n",
    "METACHD <- METAD(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### ID ###\n",
    "print(\"ID\")\n",
    "\n",
    "phenolist <- list(nfidD_finB[nfidD_finB$pheno==\"intd\",])\n",
    "phenolistS <- list(SnfidD_finB[SnfidD_finB$pheno==\"intd\",])\n",
    "\n",
    "METAID <- METAD(phenolist,phenolistS,ll)\n",
    "\n",
    "\n",
    "### SCZ ###\n",
    "print(\"SCZ\")\n",
    "\n",
    "phenolist <- list(sweD2_nfeB[sweD2_nfeB$pheno==\"scz\",],dbsD_nfeB[dbsD_nfeB$pheno==\"SCZ\",])\n",
    "phenolistS <- list(SsweD2_nfeB[SsweD2_nfeB$pheno==\"scz\",],SdbsD_nfeB[SdbsD_nfeB$pheno==\"SCZ\",])\n",
    "\n",
    "\n",
    "METASCZ <- METAD(phenolist,phenolistS,ll)\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"SCZ\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"SCZ\",])\n",
    "\n",
    "\n",
    "METASCZDBS <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"SCZ_PURE\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"SCZ_PURE\",])\n",
    "\n",
    "\n",
    "METASCZP <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"SCZ_UNPURE\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"SCZ_UNPURE\",])\n",
    "\n",
    "\n",
    "METASCZNP <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"SCZ_UNPUREID\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"SCZ_UNPUREID\",])\n",
    "\n",
    "\n",
    "METASCZNPID <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "phenolist <- list(dbsD3_nfeB[dbsD3_nfeB$pheno==\"SCZ\",])\n",
    "phenolistS <- list(SdbsD3_nfeB[SdbsD3_nfeB$pheno==\"SCZ\",])\n",
    "\n",
    "\n",
    "METASCZFEMALE <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "phenolist <- list(dbsD4_nfeB[dbsD4_nfeB$pheno==\"SCZ\",])\n",
    "phenolistS <- list(SdbsD4_nfeB[SdbsD4_nfeB$pheno==\"SCZ\",])\n",
    "\n",
    "\n",
    "METASCZMALE <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "### AUTISM ###\n",
    "print(\"AUTISM\")\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"AUTISM\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"AUTISM\",])\n",
    "\n",
    "\n",
    "METAAUTISM <- METAD(phenolist,phenolistS,ll)\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"AUTISM_PURE\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"AUTISM_PURE\",])\n",
    "\n",
    "\n",
    "METAAUTISMP <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"AUTISM_UNPURE\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"AUTISM_UNPURE\",])\n",
    "\n",
    "\n",
    "METAAUTISMNP <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"AUTISM_UNPUREID\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"AUTISM_UNPUREID\",])\n",
    "\n",
    "\n",
    "METAAUTISMNPID <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "phenolist <- list(dbsD3_nfeB[dbsD3_nfeB$pheno==\"AUTISM\",])\n",
    "phenolistS <- list(SdbsD3_nfeB[SdbsD3_nfeB$pheno==\"AUTISM\",])\n",
    "\n",
    "\n",
    "METAAUTISMFEMALE <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "phenolist <- list(dbsD4_nfeB[dbsD4_nfeB$pheno==\"AUTISM\",])\n",
    "phenolistS <- list(SdbsD4_nfeB[SdbsD4_nfeB$pheno==\"AUTISM\",])\n",
    "\n",
    "\n",
    "METAAUTISMMALE <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### ADHD ###\n",
    "print(\"ADHD\")\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"ADHD\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"ADHD\",])\n",
    "\n",
    "\n",
    "METAADHD <- METAD(phenolist,phenolistS,ll)\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"ADHD_PURE\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"ADHD_PURE\",])\n",
    "\n",
    "METAADHDP <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"ADHD_UNPURE\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"ADHD_UNPURE\",])\n",
    "\n",
    "METAADHDNP <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"ADHD_UNPUREID\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"ADHD_UNPUREID\",])\n",
    "\n",
    "METAADHDNPID <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "phenolist <- list(dbsD3_nfeB[dbsD3_nfeB$pheno==\"ADHD\",])\n",
    "phenolistS <- list(SdbsD3_nfeB[SdbsD3_nfeB$pheno==\"ADHD\",])\n",
    "\n",
    "METAADHDFEMALE <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "phenolist <- list(dbsD4_nfeB[dbsD4_nfeB$pheno==\"ADHD\",])\n",
    "phenolistS <- list(SdbsD4_nfeB[SdbsD4_nfeB$pheno==\"ADHD\",])\n",
    "\n",
    "\n",
    "METAADHDMALE <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "\n",
    "### BP ####\n",
    "print(\"BP\")\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"BP\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"BP\",])\n",
    "\n",
    "\n",
    "METABP <- METAD(phenolist,phenolistS,ll)\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"BP_PURE\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"BP_PURE\",])\n",
    "\n",
    "METABPP <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"BP_UNPURE\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"BP_UNPURE\",])\n",
    "\n",
    "METABPNP <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "phenolist <- list(dbsD_nfeB[dbsD_nfeB$pheno==\"BP_UNPUREID\",])\n",
    "phenolistS <- list(SdbsD_nfeB[SdbsD_nfeB$pheno==\"BP_UNPUREID\",])\n",
    "\n",
    "METABPNPID <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "phenolist <- list(dbsD3_nfeB[dbsD3_nfeB$pheno==\"BP\",])\n",
    "phenolistS <- list(SdbsD3_nfeB[SdbsD3_nfeB$pheno==\"BP\",])\n",
    "\n",
    "METABPFEMALE <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "phenolist <- list(dbsD4_nfeB[dbsD4_nfeB$pheno==\"BP\",])\n",
    "phenolistS <- list(SdbsD4_nfeB[SdbsD4_nfeB$pheno==\"BP\",])\n",
    "\n",
    "METABPMALE <- METAD(phenolist,NULL,ll)\n",
    "\n",
    "\n",
    "save(list = ls(all.names = TRUE)[grep(\"^META\",ls(all.names = TRUE))], file = paste0(path,\"all_results_association.Rdata\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hail",
   "language": "python",
   "name": "hail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}